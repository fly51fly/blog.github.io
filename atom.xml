<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>爱可可小窝</title>
  
  <subtitle>@爱可可-爱生活 的学习与思考</subtitle>
  <link href="https://blog.aicoco.net/atom.xml" rel="self"/>
  
  <link href="https://blog.aicoco.net/"/>
  <updated>2023-08-06T01:04:37.813Z</updated>
  <id>https://blog.aicoco.net/</id>
  
  <author>
    <name>Guang Chen</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>大语言模型开源的利与弊</title>
    <link href="https://blog.aicoco.net/2023/08/06/llm-vs-oss/"/>
    <id>https://blog.aicoco.net/2023/08/06/llm-vs-oss/</id>
    <published>2023-08-06T01:00:32.000Z</published>
    <updated>2023-08-06T01:04:37.813Z</updated>
    
    <content type="html"><![CDATA[<p>先对以大型语言模型(LLM)为代表的大模型的开源和代码项目的开源做个简单比较：</p><table><thead><tr><th></th><th>大模型的开源</th><th>代码项目的开源</th></tr></thead><tbody><tr><td>开放内容</td><td>预训练的模型，主要是网络结构和参数，一般不开放训练数据和训练代码（以及训练过程&amp;技巧）。</td><td>为实现特定功能或应用编写的代码或脚本。</td></tr><tr><td>潜在风险</td><td>可能输出有偏见、不准确或误导性信息；存在滥用风险，用于钓鱼、恶意软件编写等。</td><td>可能存在漏洞或错误，被恶意利用（攻击）。</td></tr><tr><td>修改和改进</td><td>由于缺少训练细节（数据&amp;代码），以及算力成本高昂，难以修改模型本身，但可进行微调（小范围或小幅度调整模型参数）。</td><td>可直接修改、增加功能或优化。</td></tr><tr><td>存储和分发</td><td>由于体量巨大，存储和分发有一定困难，一般通过网盘或大模型托管方(HuggingFace等)进行分发。</td><td>通常体积较小，更容易存储和分发。</td></tr><tr><td>分发和使用限制</td><td>除了和开源代码相同的开源许可证之外，可能还有其他额外限制（比如 Llama 2 月活超 7 亿不能用等）</td><td>根据开源许可证的不同，会要求衍生作品同一许可证分发、非商业使用等。</td></tr></tbody></table><p>某种程度上，开源的大模型，有点像编译后的二进制文件，由于没有源码（对于大模型来说是训练数据和训练过程，以及训练的算力成本巨大），完全重构几乎不可能，只能通过局部反编译修改机器码进行注入等方式（对于大模型来说是对参数进行小范围小幅调整）小修小改。</p><p>大模型开源最大的利，在于可以吸引足够多的用户和开发者，一方面，通过微调，用于各种领域各种细分场景和任务，产生社会效益和经济效益；另一方面，用的人多了，就能更快的挖掘最佳实践、发现潜在问题，对模型开发方也能产生充分的正反馈效应。另外，公开模型的结构和权重可以帮助公众、研究者和监管机构更好地理解模型的工作原理，增强对模型的信任。从大模型运行方面，某种程度上，开源也为分布式运行提供了基础，有助于充分利用用户的分散算力、发挥模型的最大价值。</p><p>大模型开源最大的弊，恐怕在于滥用风险，现在已经可以看到一些在开源模型基础上微调的不受约束的所谓“非审核”版模型，用来生成钓鱼邮件、诈骗电话对话、生成恶意代码、制造假新闻、在问答网站提供不实答案等，其负面影响不容忽视。另外，开源可能会影响某些传统的商业化策略，尤其是当这些策略依赖于知识产权或专利时。开源模型还可能涉及许可、版权、专利等法律问题，需要特别关注以避免潜在的纠纷。</p><p>大模型闭源，类似 ChatGPT、Claude 等，利主要体现在为公司提供独特的竞争优势、保护公司的研发成果、降低某些安全风险、避免（至少是控制）不当使用、减少计算资源滥用、数据隐私和保密性等方面。</p><p>大模型闭源的弊，主要体现在缺乏透明性难以获得公众充分信任、限制广大研究者和开发者对模型的改进和创新、潜在的偏见等问题不容易被识别和纠正、对开发方的依赖导致过度的市场集中和缺乏多样性、长期维护的持久性问题、在隐私和数据处理要求更多透明度和可解释性的领域很难满足要求等。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;先对以大型语言模型(LLM)为代表的大模型的开源和代码项目的开源做个简单比较：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;大模型的开源&lt;/th&gt;
&lt;th&gt;代码项目的开源&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;t</summary>
      
    
    
    
    <category term="随笔" scheme="https://blog.aicoco.net/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
    <category term="LLM" scheme="https://blog.aicoco.net/tags/LLM/"/>
    
  </entry>
  
  <entry>
    <title>AI的认知极限</title>
    <link href="https://blog.aicoco.net/2023/08/06/the-myth-of-ai-omniscience-ais-epistemological/"/>
    <id>https://blog.aicoco.net/2023/08/06/the-myth-of-ai-omniscience-ais-epistemological/</id>
    <published>2023-08-06T00:32:32.000Z</published>
    <updated>2023-08-06T00:42:50.757Z</updated>
    
    <content type="html"><![CDATA[<p>原文：<a href="https://cpwalker.substack.com/p/the-myth-of-ai-omniscience-ais-epistemological">The Myth of AI Omniscience: AI’s Epistemological Limits</a></p><p><strong>标题</strong>：对AI全知全能的误解：AI 的认知极限</p><p><strong>摘要</strong>：<br>文章探讨了关于AI的普遍误解，特别是关于AI是否能够“理解宇宙的真实本质”。作者指出，尽管AI在许多方面都表现出了强大的能力，但它仍然受到人类知识和理解的限制。大型语言模型（LLM）如GPT-4只能反映出我们当前对宇宙的理解，而不能超越这一点。此外，所有的AI模型都是基于人类的知识和理解来训练的，因此它们只能透过人类的眼睛“看到”宇宙。作者呼吁我们摒弃对AI神化的看法，并关注真正重要的AI问题，如模型偏见、深度伪造和失业问题。</p><p><strong>启发</strong>：  </p><ol><li><strong>AI的知识边界</strong>：尽管AI在许多任务上表现出色，但它仍然受到其训练数据的限制。这意味着AI只能反映出人类当前的知识和理解，而不能超越这些边界。  </li><li><strong>人类的角色</strong>：AI的知识和理解是基于人类的知识和理解来训练的，这意味着AI的输出是人类知识的一个镜像，而不是一个独立的、超越人类的知识源。  </li><li><strong>AI的真正挑战</strong>：我们应该关注真正重要的AI问题，而不是被对AI的过度神话化所迷惑。这包括如何确保AI的公正性、如何防止AI被用于制造虚假信息，以及如何确保AI不会导致大规模的失业。</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;原文：&lt;a href=&quot;https://cpwalker.substack.com/p/the-myth-of-ai-omniscience-ais-epistemological&quot;&gt;The Myth of AI Omniscience: AI’s Epistemologi</summary>
      
    
    
    
    <category term="文摘" scheme="https://blog.aicoco.net/categories/%E6%96%87%E6%91%98/"/>
    
    
    <category term="Research" scheme="https://blog.aicoco.net/tags/Research/"/>
    
  </entry>
  
  <entry>
    <title>科学思维的能力是否是智慧的核心本质？</title>
    <link href="https://blog.aicoco.net/2023/08/06/cargo-cult-ai/"/>
    <id>https://blog.aicoco.net/2023/08/06/cargo-cult-ai/</id>
    <published>2023-08-06T00:11:02.000Z</published>
    <updated>2023-08-06T00:25:32.761Z</updated>
    
    <content type="html"><![CDATA[<p>原文：<a href="https://queue.acm.org/detail.cfm?id=3595860">Cargo Cult AI</a></p><p><strong>摘要</strong>：<br>文章探讨了人工智能（AI）与真正的科学思维之间的差异。讨论了科学思维作为智能的核心要素，以及人类倾向于轻易相信与科学不符的神奇和幻想。作者指出类似GPT-4这样的大型语言模型被认为是早期版本的AGI（人工通用智能），但这种观点令人不安。现代AI模型虽然可以提问并回答问题，但无法复制人类科学思维，尤其是在扩展可验证知识边界方面的能力。对于物理学等领域，神经网络模型相对于牛顿的万有引力理论在普适性上存在局限性。</p><p>文章还指出，人们在使用AI进行因果推断时需要谨慎，因为神经网络在识别数据相关性方面非常擅长，但却不擅长建立因果关系。在医学诊断等领域，AI在建立因果关系方面应用已经越来越多，但这也会导致类似于人类货物崇拜（Cargo Cult）的情况出现。</p><p>作者认为，AI和AGI研究提供了了解人类思维这一未解决科学问题的机会，但目前的AI模型在理解人类思维方面还有很多工作要做。文章最后表示对AI和AGI的未来持乐观态度，并指出需要采用新的算法方法来超越纯经验推理的界限，以实现更强大的AGI。</p><p>总之，该文探讨了AI在科学思维和因果推断方面的局限性，以及对未来AI和AGI发展的展望。</p><p><strong>启发</strong>：  </p><ol><li><strong>科学思维与AI</strong>：尽管AI在许多任务上表现出色，但它是否真正拥有科学的思维方式仍然是一个问题。真正的科学思维需要对假设进行严格的调查和验证，而不是仅仅基于数据进行预测。  </li><li><strong>AI的局限性</strong>：大型语言模型如GPT-4虽然在许多任务上表现出色，但它们缺乏真正的科学探究的能力。这意味着，尽管它们可以生成看似合理的答案，但这些答案可能缺乏真正的科学依据。  </li><li><strong>人与AI的互动</strong>：当我们依赖AI为我们提供答案时，我们需要意识到它的局限性。AI的输出应该被视为一个可能有用的相关指标，而不是作为因果关系的决定性证据。</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;原文：&lt;a href=&quot;https://queue.acm.org/detail.cfm?id=3595860&quot;&gt;Cargo Cult AI&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;摘要&lt;/strong&gt;：&lt;br&gt;文章探讨了人工智能（AI）与真正的科学思维之间的差异。讨论了科</summary>
      
    
    
    
    <category term="文摘" scheme="https://blog.aicoco.net/categories/%E6%96%87%E6%91%98/"/>
    
    
    <category term="Research" scheme="https://blog.aicoco.net/tags/Research/"/>
    
  </entry>
  
  <entry>
    <title>AI不会取代人类，但使用AI的人将取代不使用AI的人</title>
    <link href="https://blog.aicoco.net/2023/08/06/ai-wont-replace-humans-but-humans-with-ai-will-replace-humans-without-ai/"/>
    <id>https://blog.aicoco.net/2023/08/06/ai-wont-replace-humans-but-humans-with-ai-will-replace-humans-without-ai/</id>
    <published>2023-08-05T23:17:24.000Z</published>
    <updated>2023-08-05T23:22:24.760Z</updated>
    
    <content type="html"><![CDATA[<p>原文：<a href="https://hbr.org/2023/08/ai-wont-replace-humans-but-humans-with-ai-will-replace-humans-without-ai">AI Won’t Replace Humans — But Humans With AI Will Replace Humans Without AI</a></p><p>内容要点：  </p><ul><li>与互联网大大降低了信息传输的成本一样，AI将降低认知的成本。  </li><li>虽然很多人担心AI会取代人类的工作，但真正的趋势是，拥有AI技能的人类将会取代那些没有AI技能的人类。这意味着AI不是一个威胁，而是一个工具，可以增强人类的能力。  </li><li>AI不仅仅是为技术工作者设计的，所有员工都应该了解和利用AI。这意味着企业需要为所有员工提供AI培训和资源，而不仅仅是技术团队。  </li><li>AI的应用不仅仅是在高技术领域，它可以应用在任何需要思考的地方，AI的潜在应用是无限的。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;原文：&lt;a href=&quot;https://hbr.org/2023/08/ai-wont-replace-humans-but-humans-with-ai-will-replace-humans-without-ai&quot;&gt;AI Won’t Replace Humans — B</summary>
      
    
    
    
    <category term="文摘" scheme="https://blog.aicoco.net/categories/%E6%96%87%E6%91%98/"/>
    
    
    <category term="Research" scheme="https://blog.aicoco.net/tags/Research/"/>
    
  </entry>
  
  <entry>
    <title>创新研究的原则和启示</title>
    <link href="https://blog.aicoco.net/2023/08/01/quick-thoughts-on-research/"/>
    <id>https://blog.aicoco.net/2023/08/01/quick-thoughts-on-research/</id>
    <published>2023-08-01T00:03:43.000Z</published>
    <updated>2023-08-01T00:45:47.781Z</updated>
    
    <content type="html"><![CDATA[<p>原文：<a href="https://michaelnotebook.com/qtr/index.html">Quick thoughts on research</a></p><h2 id="创新研究的原则和启示"><a href="#创新研究的原则和启示" class="headerlink" title="创新研究的原则和启示"></a>创新研究的原则和启示</h2><h3 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h3><ul><li>作者分享了自己在理论物理、计算机科学、思维工具和元科学领域的经验，提出创新研究工作的原则和启示。</li><li>强调分享研究思考对整个研究社区的益处。</li></ul><h3 id="警惕普适原则"><a href="#警惕普适原则" class="headerlink" title="警惕普适原则"></a>警惕普适原则</h3><ul><li>研究原则不是普适法则，因人而异，因情况而异。</li><li>需要一系列灵活的启示，适应不同的情况和变化。</li><li>在事情进展顺利时，继续保持，而在陷入困境时，尝试其他启示。</li><li>坚持和决心是好研究者的重要品质，但同时要具备灵活和重新调整方向的能力。</li></ul><h3 id="了解自己的工作方式"><a href="#了解自己的工作方式" class="headerlink" title="了解自己的工作方式"></a>了解自己的工作方式</h3><ul><li>理解自己的独特工作方式，可能与他人不同。</li><li>伟大的研究者通常有非传统的工作方法。</li></ul><h3 id="警惕建议"><a href="#警惕建议" class="headerlink" title="警惕建议"></a>警惕建议</h3><ul><li>建议可能有价值，也可能不适合个人情况。</li><li>尊重对自己有共鸣和激励的建议，但如果不适用，不要灰心。</li><li>避免被不适合自己的建议束缚。</li></ul><h3 id="动力-Momentum"><a href="#动力-Momentum" class="headerlink" title="动力(Momentum)"></a>动力(Momentum)</h3><ul><li>动力(Momentum)在研究中至关重要。</li><li>保持动力，持续自我激励。</li></ul><h3 id="合作就像是相互指教"><a href="#合作就像是相互指教" class="headerlink" title="合作就像是相互指教"></a>合作就像是相互指教</h3><ul><li>最佳合作往往涉及相互指教，帮助彼此成长。</li><li>从不寻常的个体中学习可能比从技术上有价值的知识更有价值。</li></ul><h3 id="寻找比你年轻和年长的导师"><a href="#寻找比你年轻和年长的导师" class="headerlink" title="寻找比你年轻和年长的导师"></a>寻找比你年轻和年长的导师</h3><ul><li>向比自己年轻和年长得多的人学习。</li><li>学会与不同年龄段的人交流，这是一种竞争优势。</li></ul><h3 id="赋能和激励"><a href="#赋能和激励" class="headerlink" title="赋能和激励"></a>赋能和激励</h3><ul><li>以赋能的态度接触他人，培养这种能力。</li><li>培养这种能力(a power of enablement)是一种技巧。</li></ul><h3 id="研究前沿的动态性"><a href="#研究前沿的动态性" class="headerlink" title="研究前沿的动态性"></a>研究前沿的动态性</h3><ul><li>研究前沿可能会突然转移到其他领域，如波前比粒子移动得更快。</li><li>不同的人会以不同的方式应对这种变化。</li><li>避免追逐潮流，更好的方式是寻找自己独特的研究方向。</li></ul><h3 id="所做问题的重要性"><a href="#所做问题的重要性" class="headerlink" title="所做问题的重要性"></a>所做问题的重要性</h3><ul><li>研究问题的重要性有很大影响，专注于发现重要问题。</li><li>选择在丰饶的领域工作，并培养对基础研究的良好品味。</li></ul><h3 id="点滴收获"><a href="#点滴收获" class="headerlink" title="点滴收获"></a>点滴收获</h3><ul><li>从经验丰富的研究者那里学到的无形知识非常有价值。</li><li>避免愤世嫉俗，避免疲劳，如果有必要，做出改变。</li></ul><h3 id="日常工作和动力"><a href="#日常工作和动力" class="headerlink" title="日常工作和动力"></a>日常工作和动力</h3><ul><li>日常工作为深入洞察打下基础。</li><li>行动会带来动力，避免拖延。</li></ul><h3 id="了解和接纳自己"><a href="#了解和接纳自己" class="headerlink" title="了解和接纳自己"></a>了解和接纳自己</h3><ul><li>诚实地了解自己的动机，作出相应的工作。</li><li>勇气、想象力和决心通常比智力更重要。</li></ul><h3 id="教授和学习"><a href="#教授和学习" class="headerlink" title="教授和学习"></a>教授和学习</h3><ul><li>教授能帮助加深对知识的理解。</li><li>通过努力提高教学水平可以学到更多。</li></ul><h3 id="尝试愚蠢的工作"><a href="#尝试愚蠢的工作" class="headerlink" title="尝试愚蠢的工作"></a>尝试愚蠢的工作</h3><ul><li>进行愚蠢的实验，有时会带来重要发现。</li></ul><h3 id="寻找重要问题"><a href="#寻找重要问题" class="headerlink" title="寻找重要问题"></a>寻找重要问题</h3><ul><li>选择有意义的项目，能够作出独特贡献的项目。</li><li>向有经验的研究者寻求指导，找到有意义的项目。</li></ul><h3 id="勇气和信念"><a href="#勇气和信念" class="headerlink" title="勇气和信念"></a>勇气和信念</h3><ul><li>勇气是做出重大研究的关键。</li><li>构建自己的信念，超越现有观念。</li></ul><h3 id="分享你的理解"><a href="#分享你的理解" class="headerlink" title="分享你的理解"></a>分享你的理解</h3><ul><li>与支持你的同行分享你的想法。</li><li>分享你的工作有助于完善和发展想法。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;原文：&lt;a href=&quot;https://michaelnotebook.com/qtr/index.html&quot;&gt;Quick thoughts on research&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;创新研究的原则和启示&quot;&gt;&lt;a href=&quot;#创新研究的原则和启示&quot; clas</summary>
      
    
    
    
    <category term="文摘" scheme="https://blog.aicoco.net/categories/%E6%96%87%E6%91%98/"/>
    
    
    <category term="Research" scheme="https://blog.aicoco.net/tags/Research/"/>
    
  </entry>
  
  <entry>
    <title>是什么让Stack Overflow日渐衰落？</title>
    <link href="https://blog.aicoco.net/2023/08/01/the-fall-of-stack-overflow-explained/"/>
    <id>https://blog.aicoco.net/2023/08/01/the-fall-of-stack-overflow-explained/</id>
    <published>2023-07-31T23:20:04.000Z</published>
    <updated>2023-07-31T23:44:16.150Z</updated>
    
    <content type="html"><![CDATA[<p>原文：<a href="https://newsletter.devmoh.co/p/the-fall-of-stack-overflow-explained">The Fall of Stack Overflow, Explained</a></p><h2 id="Stack-Overflow-的衰落"><a href="#Stack-Overflow-的衰落" class="headerlink" title="Stack Overflow 的衰落"></a>Stack Overflow 的衰落</h2><p>一篇名为<a href="https://observablehq.com/d/fb670a74e01d9f54">《Stack Overflow的衰落》</a>的文章迅速传播，用数据详细描述了 Stack Overflow 在过去一年半流量下降了35-50%。</p><h3 id="1-原因一：Google-Analytics-的变化"><a href="#1-原因一：Google-Analytics-的变化" class="headerlink" title="1. 原因一：Google Analytics 的变化"></a>1. 原因一：Google Analytics 的变化</h3><p>2022年5月，由于隐私法律的原因，Google Analytics 改变了 cookie 的存储方式，导致流量报告出现了15%的下降。实际上，Stack Overflow 并未失去50%的流量，而是约35%。</p><h3 id="2-原因二：Stack-Overflow-对用户不友好"><a href="#2-原因二：Stack-Overflow-对用户不友好" class="headerlink" title="2. 原因二：Stack Overflow 对用户不友好"></a>2. 原因二：Stack Overflow 对用户不友好</h3><p>Stack Overflow 是一个用于提问的网站，但令人惊讶的是，它却是网络上最具有毒性和敌对性的地方之一，表现出被动攻击的方式。十多年来，我们见证了成千上万的有关 Stack Overflow 敌对性的抱怨，因此，Stack Overflow 的敌对性和衰落并不是新鲜事。</p><h3 id="3-原因三：Google-搜索排名下降"><a href="#3-原因三：Google-搜索排名下降" class="headerlink" title="3. 原因三：Google 搜索排名下降"></a>3. 原因三：Google 搜索排名下降</h3><p>Stack Overflow 的搜索结果在 Google 上排名下降，不再总是第一，有时甚至不会出现在第一页。</p><h3 id="4-原因四：AI-的影响"><a href="#4-原因四：AI-的影响" class="headerlink" title="4. 原因四：AI 的影响"></a>4. 原因四：AI 的影响</h3><p>AI(人工智能)也对 Stack Overflow 的衰落产生了影响。ChatGPT 特别适用于编程，它的发布加速了 Stack Overflow 的衰落。然而，AI 的兴起并非完全是最主要的原因，Stack Overflow 的衰落由来已久。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Stack Overflow 的流量衰退由多个因素共同导致。Google Analytics 的变化、对用户不友好以及 Google 搜索排名下降是其流量下降的原因之一。同时，AI 的兴起也对其产生了影响，但这并非唯一原因。Stack Overflow 作为一个免费提供数据的平台，为人工智能的训练做出了贡献，但AI的快速发展可能会导致未来训练数据的减少。</p><p>AI在解决问题的速度、友好程度和跟进上具有优势，但它仍然是工具，而非替代品。Stack Overflow 可能会继续衰落，特别是在 Google 的 Search Labs 推出后。Stack Overflow 已经推出了 OverflowAI 作为对衰落的回应，AI 和 Stack Overflow 可能在未来相互竞争。</p><p>然而，Stack Overflow 仍然是一个宝贵的资源，它对于许多开发者来说仍然非常有用。AI 和 Stack Overflow 在不同场景下可能会互补，而不是替代彼此。开发者可以根据具体情况选择使用合适的工具来提高生产力和解决问题。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;原文：&lt;a href=&quot;https://newsletter.devmoh.co/p/the-fall-of-stack-overflow-explained&quot;&gt;The Fall of Stack Overflow, Explained&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;St</summary>
      
    
    
    
    <category term="文摘" scheme="https://blog.aicoco.net/categories/%E6%96%87%E6%91%98/"/>
    
    
    <category term="ChatGPT" scheme="https://blog.aicoco.net/tags/ChatGPT/"/>
    
    <category term="StackOverflow" scheme="https://blog.aicoco.net/tags/StackOverflow/"/>
    
  </entry>
  
  <entry>
    <title>ChatGPT时代怎么教编程</title>
    <link href="https://blog.aicoco.net/2023/07/24/teaching-programming-in-the-age-of-chatgpt/"/>
    <id>https://blog.aicoco.net/2023/07/24/teaching-programming-in-the-age-of-chatgpt/</id>
    <published>2023-07-24T13:38:01.000Z</published>
    <updated>2023-07-24T13:48:34.687Z</updated>
    
    <content type="html"><![CDATA[<p>原文：<a href="https://www.oreilly.com/radar/teaching-programming-in-the-age-of-chatgpt/">Teaching Programming in the Age of ChatGPT</a></p><h3 id="在ChatGPT时代教授编程：计算机教师的适应计划"><a href="#在ChatGPT时代教授编程：计算机教师的适应计划" class="headerlink" title="在ChatGPT时代教授编程：计算机教师的适应计划"></a>在ChatGPT时代教授编程：计算机教师的适应计划</h3><h4 id="主要信息"><a href="#主要信息" class="headerlink" title="主要信息"></a>主要信息</h4><ul><li>ChatGPT等AI编程助手的出现引发了计算机编程教师的关注，他们面临如何调整教学策略的挑战。</li><li>短期计划：教师希望阻止学生作弊，避免依赖AI工具，采取一些应对措施，如限制工具使用、强化考试方式等。</li><li>长期计划（抵制AI工具）：教师担心学生可能不掌握编程基础，提出设计“AI-proof”作业和评估方法的想法。</li><li>长期计划（拥抱AI工具）：教师认为AI编程工具是未来的趋势，可在教学中利用这些工具来帮助学生更好地学习编程。</li></ul><h4 id="详细重点内容"><a href="#详细重点内容" class="headerlink" title="详细重点内容"></a>详细重点内容</h4><h5 id="短期计划：阻止学生作弊"><a href="#短期计划：阻止学生作弊" class="headerlink" title="短期计划：阻止学生作弊"></a>短期计划：阻止学生作弊</h5><ul><li>计算机教师普遍认为AI编程助手可能带来学生作弊的问题，并采取一些措施来阻止学生过度依赖这些工具。</li><li>教师担心学生不会深入思考问题，而只是依赖AI工具的答案。</li><li>一些教师采取限制AI工具使用、调整考试方式等短期措施来解决这个问题。</li></ul><h5 id="长期计划（抵制AI工具）：保障学生学习编程基础"><a href="#长期计划（抵制AI工具）：保障学生学习编程基础" class="headerlink" title="长期计划（抵制AI工具）：保障学生学习编程基础"></a>长期计划（抵制AI工具）：保障学生学习编程基础</h5><ul><li>一些教师认为使用AI工具可能导致学生不掌握编程基础，提出设计“AI-proof”作业和评估方法的想法。</li><li>通过使用定制库或增加本地文化和语言背景等方法，设计作业和评估以减少AI工具的影响。</li><li>教师认为这些方法不仅有助于保障学生学习编程基础，还能够让学生更深入地思考编程问题。</li></ul><h5 id="长期计划（拥抱AI工具）：帮学生为未来职业需求做准备"><a href="#长期计划（拥抱AI工具）：帮学生为未来职业需求做准备" class="headerlink" title="长期计划（拥抱AI工具）：帮学生为未来职业需求做准备"></a>长期计划（拥抱AI工具）：帮学生为未来职业需求做准备</h5><ul><li>许多教师认为AI编程工具将成为程序员的标准工具，希望通过教学中利用这些工具来帮助学生为未来的职业需求做准备。</li><li>教师认为AI工具有助于学生更快地学习编程语法，并能够更深入地学习程序设计和工程。</li><li>教师还认为AI工具有助于提供个性化帮助，例如解释为什么某段代码出错等。</li></ul><h5 id="研究展望：有效、公平和道德地使用AI编程工具"><a href="#研究展望：有效、公平和道德地使用AI编程工具" class="headerlink" title="研究展望：有效、公平和道德地使用AI编程工具"></a>研究展望：有效、公平和道德地使用AI编程工具</h5><ul><li>这些发现是早期的研究成果，计算机教师对AI编程工具的使用还没有形成共识的最佳实践。</li><li>研究提出了一些关于如何开发、应用和评估AI编程工具的问题，包括学习者对AI生成代码的理解、AI工具的应用和评估等。</li></ul><h4 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h4><ul><li>计算机编程教师面临着调整教学策略的挑战，需要平衡抵制和拥抱AI编码工具的使用。</li><li>在长期计划中，教师需要关注学生学习编程基础的同时，也要充分利用AI工具提供的优势，为学生未来的职业需求做好准备。</li><li>进一步研究和探讨如何有效、公平和道德地使用AI编程工具对教育领域具有重要意义。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;原文：&lt;a href=&quot;https://www.oreilly.com/radar/teaching-programming-in-the-age-of-chatgpt/&quot;&gt;Teaching Programming in the Age of ChatGPT&lt;/a&gt;&lt;/p&gt;</summary>
      
    
    
    
    <category term="文摘" scheme="https://blog.aicoco.net/categories/%E6%96%87%E6%91%98/"/>
    
    
    <category term="ChatGPT" scheme="https://blog.aicoco.net/tags/ChatGPT/"/>
    
    <category term="Programming" scheme="https://blog.aicoco.net/tags/Programming/"/>
    
    <category term="Teaching" scheme="https://blog.aicoco.net/tags/Teaching/"/>
    
  </entry>
  
  <entry>
    <title>让LLM总是用事实而不是虚构来回答问题</title>
    <link href="https://blog.aicoco.net/2023/07/24/teach-your-llm-vector-sql/"/>
    <id>https://blog.aicoco.net/2023/07/24/teach-your-llm-vector-sql/</id>
    <published>2023-07-24T13:08:31.000Z</published>
    <updated>2023-07-24T13:23:13.757Z</updated>
    
    <content type="html"><![CDATA[<p>原文：<a href="https://blog.myscale.com/2023/07/17/teach-your-llm-vector-sql/">Teach your LLM to always answer with facts not fiction</a></p><h3 id="LLM幻觉与使用Vector-SQL减少幻觉"><a href="#LLM幻觉与使用Vector-SQL减少幻觉" class="headerlink" title="LLM幻觉与使用Vector SQL减少幻觉"></a>LLM幻觉与使用Vector SQL减少幻觉</h3><h4 id="主要信息"><a href="#主要信息" class="headerlink" title="主要信息"></a>主要信息</h4><ul><li>LLM（Large Language Model）是一种高级AI系统，可以回答广泛范围的问题，但在陌生话题上可能出现幻觉现象。</li><li>幻觉是指在缺乏外部刺激的情况下，产生具有真实感知质量的感知错误。</li><li>增加外部知识可以减少LLM幻觉的出现。</li><li>使用Vector SQL可以实现精细粒度的向量搜索，从而提高LLM回答问题的准确性和效率。</li></ul><h4 id="详细重点内容"><a href="#详细重点内容" class="headerlink" title="详细重点内容"></a>详细重点内容</h4><h5 id="LLM幻觉与外部知识"><a href="#LLM幻觉与外部知识" class="headerlink" title="LLM幻觉与外部知识"></a>LLM幻觉与外部知识</h5><ul><li>LLM并不是无懈可击的，可能在陌生话题上产生幻觉。为了减少幻觉，应加入外部知识，以指导LLM向准确和正确的回答迈进。</li><li>外部知识可以来自搜索引擎、数字图书馆等多个来源，并应与问题相关。</li></ul><h5 id="向量SQL与复杂搜索查询"><a href="#向量SQL与复杂搜索查询" class="headerlink" title="向量SQL与复杂搜索查询"></a>向量SQL与复杂搜索查询</h5><ul><li>向量SQL是一种强大的工具，用于构建复杂的搜索查询，它支持多种数据类型和函数。</li><li>向量SQL可以与SQL数据库集成，通过精细粒度的向量搜索提供准确的答案。</li><li>向量SQL的优势包括增加灵活性、提高效率、易于学习以及对LLM友好。</li></ul><h5 id="使用Vector-SQL自动化整个过程"><a href="#使用Vector-SQL自动化整个过程" class="headerlink" title="使用Vector SQL自动化整个过程"></a>使用Vector SQL自动化整个过程</h5><ul><li>LLM可以学习从其数据源中查询数据，并使用SQL查询来自动化整个回答过程。</li><li>向量SQL的使用将为复杂搜索查询带来许多好处，并为LLM提供高效准确的回答。</li></ul><h5 id="MyScale和其他数据库解决方案"><a href="#MyScale和其他数据库解决方案" class="headerlink" title="MyScale和其他数据库解决方案"></a>MyScale和其他数据库解决方案</h5><ul><li>MyScale等数据库解决方案正在将向量搜索集成到其功能中，从而提供更强大的搜索和回答能力。</li><li>同时，越来越多的应用开发人员开始在他们的应用程序中使用向量搜索和SQL，以利用LLM的优势。</li></ul><h4 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h4><ul><li>LLM幻觉在现实中是普遍存在的。减少幻觉的最实用方法是在问题中添加外部知识，以实现高效准确的回答。</li><li>向量SQL是一种强大的工具，可以帮助构建复杂的搜索查询，提高LLM回答问题的准确性和效率。</li><li>通过使用MyScale等数据库解决方案，向量搜索正在成为越来越受欢迎的工具，为LLM系统提供更强大的搜索和回答能力。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;原文：&lt;a href=&quot;https://blog.myscale.com/2023/07/17/teach-your-llm-vector-sql/&quot;&gt;Teach your LLM to always answer with facts not fiction&lt;/a&gt;&lt;/p</summary>
      
    
    
    
    <category term="文摘" scheme="https://blog.aicoco.net/categories/%E6%96%87%E6%91%98/"/>
    
    
    <category term="LLM" scheme="https://blog.aicoco.net/tags/LLM/"/>
    
    <category term="SQL" scheme="https://blog.aicoco.net/tags/SQL/"/>
    
  </entry>
  
  <entry>
    <title>人和大模型之间最大的差距</title>
    <link href="https://blog.aicoco.net/2023/07/23/differences-between-human-and-ai/"/>
    <id>https://blog.aicoco.net/2023/07/23/differences-between-human-and-ai/</id>
    <published>2023-07-23T06:55:53.000Z</published>
    <updated>2023-07-23T07:01:30.071Z</updated>
    
    <content type="html"><![CDATA[<p>非常认同Andrej Kalpathy在“State of GPT”报告里分享的观点（以下为宝玉搬运字幕版，中文翻译质量很高），结合我的思考进一步阐述如下：</p><p><a href="https://weibo.com/tv/show/1034:4906247460421679">微软2003年Build大会演讲：如何训练和应用GPT</a></p><p>人和大模型之间最大的差距，在于思考过程和追求答案的方向。</p><p>人有内心独白，会调动经验，拆解问题，进行复杂的思考过程，追求<strong>合理、准确</strong>的答案，注重答案<strong>从内容到形式的“优雅”<strong>，即我们常说的”</strong>信·达·雅</strong>“。人类思维涉及更深层次的推理和判断，结合自身人格，做出对道德、情感和价值的独立考量。更会对答案进行<strong>反思和批判</strong>，从内外得到的反馈中，得到精神享受或改进经验。</p><p>相比之下，大模型（典型如LLM）没有内心独白，背靠超级广泛的事实知识，通过上下文关联调度工作记忆，追求<strong>全面综合已知语料达成的内容和形式上的最佳外推，或模仿</strong>。大模型的目标，往往在于以大量数据为基础，给出”<strong>不跑偏</strong>“的延拓，而非像人类一样进行复杂的思考过程。至于思维链，也是在上下文引导下对思考过程描述数据的模仿。最新的研究表明，大模型<strong>有一定的进行隐性”反思“的能力</strong>，即对于质量不高的回答，”心“里往往是”有数“的，但机制如何、是否鲁棒、如何利用尚无定论。</p><p><strong>提示(Prompt)<strong>的出现，一定程度上弥补了这两种认知架构之间的差异。通过设计有效的提示，人们可以引导大模型的输出，使其更接近人类的思考方式和期望的答案。提示可以提供上下文、约束和指导，使大模型更好地理解问题，并生成更准确、相关和符合人类期望的回答。本质上，就是</strong>用心智模型，引导模仿过程，达成符合我们对”智能“预期的答案</strong>。</p><p>因此，提示的使用，在人与大模型之间架起了一座桥梁，帮助弥合了两者认知架构的差异。这使得大模型能够更好地满足人类需求，并在特定任务中展现出更高的准确性和可用性。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;非常认同Andrej Kalpathy在“State of GPT”报告里分享的观点（以下为宝玉搬运字幕版，中文翻译质量很高），结合我的思考进一步阐述如下：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://weibo.com/tv/show/1034:49062474604</summary>
      
    
    
    
    <category term="随笔" scheme="https://blog.aicoco.net/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
    <category term="LLM" scheme="https://blog.aicoco.net/tags/LLM/"/>
    
    <category term="AI" scheme="https://blog.aicoco.net/tags/AI/"/>
    
  </entry>
  
  <entry>
    <title>大模型参数规模越大越好吗？</title>
    <link href="https://blog.aicoco.net/2023/07/23/effects-of-more-params/"/>
    <id>https://blog.aicoco.net/2023/07/23/effects-of-more-params/</id>
    <published>2023-07-23T06:50:16.000Z</published>
    <updated>2023-07-23T06:54:00.782Z</updated>
    
    <content type="html"><![CDATA[<p>先说结论：<strong>规模是把双刃剑，平衡点需具体权衡</strong>。</p><p>从<strong>大模型记忆论</strong>的观点来看，模型规模越大，参数越多，记忆容量越高，对整体数据分布的把握就越全面，可以增加模型在推理时的工作记忆，生成<strong>更具创新性、更多样的结果</strong>。但与此同时，随着熵增，高概率候选结果的多样化会呈指数级爆发，这就带来了一个挑战：如何在这些结果中进行优选，使得模型的输出<strong>与人类的价值观对齐</strong>。</p><p>从<strong>大模型压缩论</strong>的观点来看，大模型的目标是通过压缩世界知识来实现智能。压缩率越高，模型对<strong>核心规律的理解</strong>就越深入，因此并不需要过大的参数规模。<strong>过多的参数可能导致资源浪费</strong>，盲目扩容并不能带来更高的性能提升，这也符合“广记不如巧记”的直觉。</p><p>从<strong>大模型数据中心论</strong>的观点看，数据的质和量是决定模型能力的核心因素。更大的模型需要更多的数据来进行训练。目前，大多大模型还处在“半饥饿”状态，即它们<strong>无法得到足够多的优质数据来满足其训练需求</strong>。且世界上可用于训练大模型的优质数据已经接近极限，进一步获取优质数据，目前可见有两个来源：一是从相对质量不高的数据来源攫取数据，清洗、优化的成本巨大；二是靠大模型自己生成，且不说这种自激强化&#x2F;近亲演化过程对模型可能造成的负面影响，生成内容的合理性、事实性目前都是大问题，如何分辨和用好这些数据在未来很长一段时间都会是个待解的难题。</p><p>从<strong>模型效能</strong>的角度来看，过大的模型规模可能会导致能源浪费，实现<strong>效果和成本的平衡</strong>是一个重要考虑因素。在这种情况下，深度挖掘中小规模模型潜力，使用专家模型优化路由的方式，通过分布式集成提高总体能力可能是更优的选择。</p><p>总的来说，虽然大模型具有较高的处理和学习能力，但是我们也需要考虑到参数量、数据的质与量、模型压缩和效能等多方面的因素。这需要我们在实践中进行权衡，找到最优的解决方案。模型规模和参数量的平衡点并不是个固定的数值，甚至没有经验可以指导，需要<strong>根据具体的应用场景、数据环境、计算资源和目标进行动态权衡和调整</strong>。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;先说结论：&lt;strong&gt;规模是把双刃剑，平衡点需具体权衡&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;从&lt;strong&gt;大模型记忆论&lt;/strong&gt;的观点来看，模型规模越大，参数越多，记忆容量越高，对整体数据分布的把握就越全面，可以增加模型在推理时的工作记忆，生成&lt;strong&gt;</summary>
      
    
    
    
    <category term="随笔" scheme="https://blog.aicoco.net/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
    <category term="LLM" scheme="https://blog.aicoco.net/tags/LLM/"/>
    
    <category term="AI" scheme="https://blog.aicoco.net/tags/AI/"/>
    
  </entry>
  
  <entry>
    <title>医疗AI会取代人类医生吗？</title>
    <link href="https://blog.aicoco.net/2023/07/23/can-ai-displace-doctor/"/>
    <id>https://blog.aicoco.net/2023/07/23/can-ai-displace-doctor/</id>
    <published>2023-07-23T06:42:24.000Z</published>
    <updated>2023-07-23T06:47:32.509Z</updated>
    
    <content type="html"><![CDATA[<p>医疗除了技术问题以外，也许更重要的，会<strong>涉及对人类情感的理解和关怀</strong>。尽管AI能处理大量数据，但其在理解人类情绪和个体经历方面有限。这对处理如慢性病管理和心理健康问题等多元健康问题显得尤为重要。</p><p>每个病人都是独特的，需要全面、个性化和富有同情心的医疗服务，也就是<strong>个性化的诊疗服务</strong>。尽管AI能有效处理和分析大量信息，但其决策基于已有数据和已知规则，对新颖和独特的情况可能无法有效应对。</p><p>AI系统的构建需要包含更多<strong>多样化的经验、观点和专业知识</strong>。AI在识别模式和提供预测方面有巨大潜力，但也可能受到训练数据中固有偏见的影响，这可能导致不准确的诊断。</p><p>医疗决策不仅需要疾病和治疗的专业知识，还需要理解和考虑病人的需求和偏好，以及其他诸多因素。这一决策过程中的<strong>灵活性和人性化</strong>是AI难以实现的。</p><p>尽管AI在医学考试等基准测试上的表现已经超过了人类医生，但其<strong>在处理真实世界的复杂和模糊问题方面可能存在局限</strong>。然而，作为医生的辅助工具，AI具有巨大的潜力，可以帮助医生提高效率，减少错误。</p><p>在医疗领域，建立患者对医生的<strong>信任是至关重要的</strong>，这是AI可能需要投入更多时间和努力去实现的。此外，当出现医疗纠纷时，AI系统<strong>如何定责</strong>也是一个复杂且未解决的问题。</p><p>总而言之，现阶段的医疗AI更适合作为医生的辅助工具，而不是完全替代他们。它们可以帮助处理大量的数据和信息，提高医生的效率，尤其是在我国医疗资源下沉、社区化医疗的大背景下，但在理解和处理病人的全人性需求，以及在人性化的医疗决策方面，人类医生的作用仍然不可替代。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;医疗除了技术问题以外，也许更重要的，会&lt;strong&gt;涉及对人类情感的理解和关怀&lt;/strong&gt;。尽管AI能处理大量数据，但其在理解人类情绪和个体经历方面有限。这对处理如慢性病管理和心理健康问题等多元健康问题显得尤为重要。&lt;/p&gt;
&lt;p&gt;每个病人都是独特的，需要全面、个性</summary>
      
    
    
    
    <category term="随笔" scheme="https://blog.aicoco.net/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
    <category term="LLM" scheme="https://blog.aicoco.net/tags/LLM/"/>
    
    <category term="AI" scheme="https://blog.aicoco.net/tags/AI/"/>
    
  </entry>
  
  <entry>
    <title>最重要的编程习惯</title>
    <link href="https://blog.aicoco.net/2023/07/23/healthy-coding-habits/"/>
    <id>https://blog.aicoco.net/2023/07/23/healthy-coding-habits/</id>
    <published>2023-07-23T05:25:13.000Z</published>
    <updated>2023-07-23T05:32:45.279Z</updated>
    
    <content type="html"><![CDATA[<p>原文：<a href="https://puppycoding.com/2023/07/22/healthy-coding-habits/">The Most Important Coding Habits</a></p><p>作者在康复期躺着写下这篇文章，因为腰椎间盘突出导致了滑脱症状。他通过自己的痛苦体会认识到，最重要的编程习惯并不是代码的可读性、一致性、组织结构等方面，而是那些让我们能在未来数十年继续享受编程乐趣的习惯。</p><p>文章提到了几个重要的编程习惯，以避免因长时间久坐在键盘前而导致的健康问题：</p><ul><li><p>每日伸展：定期进行腹部和大腿肌肉的伸展运动，即使不是瑜伽爱好者，也可以在早晨或热水浴后进行，使肌肉更柔软，更有助于支撑身体。</p></li><li><p>定期休息：至少每隔一个小时起身走一走，或离开屏幕进行其他活动，不仅对身体有好处，而且对编程也有帮助。经常会有这样的情况，当你卡在一个问题上时，换下思路，回来重新尝试，往往可能会有新的灵感。</p></li><li><p>不要在深夜编程：避免熬夜编程，疲劳时编写的代码会质量较差，甚至有害，而且容易导致长时间低头弯腰，对身体造成不利影响。设定一个截止时间，坚持下来。</p></li><li><p>改善编程环境：优化编程环境，例如使用笔记本电脑支架和人体工学椅子，但即使有这些设备，仍然可能出现腰背疼痛。作者在文章中提到听说很多推荐站立式办公桌，现在也开始尝试。他认为，站立式办公桌不仅可以提高活动度，还能促进更多的休息，是一个双重受益的习惯。</p></li></ul><p>总之，这篇文章提醒了程序员要重视健康，特别是在长期编程的过程中，不良的习惯可能导致身体健康问题。通过每日伸展、定期休息、避免深夜编程和改善编程环境等习惯，可以减少对身体的伤害，享受健康的编程生涯。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;原文：&lt;a href=&quot;https://puppycoding.com/2023/07/22/healthy-coding-habits/&quot;&gt;The Most Important Coding Habits&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;作者在康复期躺着写下这篇文章，因为腰椎间盘突</summary>
      
    
    
    
    <category term="文摘" scheme="https://blog.aicoco.net/categories/%E6%96%87%E6%91%98/"/>
    
    
    <category term="Programming" scheme="https://blog.aicoco.net/tags/Programming/"/>
    
  </entry>
  
  <entry>
    <title>用AI生成数据训练AI会有问题吗？</title>
    <link href="https://blog.aicoco.net/2023/07/22/use-ai-to-train-ai/"/>
    <id>https://blog.aicoco.net/2023/07/22/use-ai-to-train-ai/</id>
    <published>2023-07-22T14:04:37.000Z</published>
    <updated>2023-07-22T14:09:36.821Z</updated>
    
    <content type="html"><![CDATA[<p>让我们从一个不那么恰当的类比开始——一个人，通过读自己原创的书稿，能受到新的启发、获得能力的提升吗？不必急着回答，因为AI大模型的学习机制，和人类的学习机制，是截然不同的。但可以肯定，至少有一点人比AI靠谱——人不会因为看自己的作品失忆、变坏、变笨，目前的AI呢，还真不一定……</p><p>首先，<strong>AI生成的数据良莠不齐，且难以分辨</strong>。以目前的大型语言模型(LLM)为例，在生成文本时，通常会在每个步骤中做出<strong>高概率候选结果的随机选择</strong>，即使在相同的上下文中，模型也可能生成不同的续写。这种随机性可以增加模型的创新性和多样性，但也可能导致质量的不稳定。虽然这些模型在处理大规模的文本数据方面表现出色，但它们并不能理解文本的含义。模型没有人类的常识、情感和道德观念，因此<strong>可能会生成不准确、不合逻辑或者不适当的内容</strong>。大语言模型的训练数据来自于网络，这意味着它们接触到的信息范围极广，包括高质量的事实表述、学术文章和低质量的网络评论及谣言甚至其它各种不良内容。如果模型在训练过程中接触到大量的低质量内容，那么它<strong>可能会学习到这些内容的不良风格和模式</strong>。如果能“去其糟粕”，将生成的数据清洗干净，那当然再好不过，可遗憾的是，尽管目前存在一些自动化的文本质量评估方法，用来评估生成文本的流畅性、一致性等，但这些方法可能<strong>无法全面评估生成文本的质量</strong>。例如，一个句子可能在语法上完全正确，但在语义上完全没有意义，或在道德层面消极甚至反社会、反人性。这使得区分AI生成的高质量和低质量文本变得非常困难。</p><p>用<strong>人工反馈强化学习(RLHF)能保证生成质量吗</strong>？RLHF是一种常用的策略，通过人工评估和反馈来调整AI模型的行为，以使其与人类价值观对齐，避免生成低质量内容。但这种方法通常需要进行大量的试错，以找到能够最大化奖励的策略。对于复杂的任务，如文本生成，这个过程可能非常复杂和耗时。<strong>RLHF虽然可以解决一些明显的问题，但可能无法从根本上解决质量问题</strong>。有些问题可能源于模型的基本架构或训练数据，通过微调很难根本解决。更进一步，在<strong>RLHF训练过程中，模型可能会忘记之前学到的一些知识</strong>，这被称为灾难性遗忘。例如，当模型在人工反馈强化学习过程中过度优化某一特定任务时，可能会忘记其他任务的知识。这可能导致模型在某些方面的能力退化。人工反馈强化学习需要大量的人工评估和反馈，这可能会<strong>消耗大量的人力和时间</strong>。而且，人的评估可能<strong>存在一定的主观性和不一致性</strong>，也可能会影响训练的效果。</p><p>综上所述，<strong>AI生成的数据质量难以保证。</strong>如果不加以区分，将包括高质量的结果和不合理、不符合逻辑，甚至反社会、反人性的结果在内的所有数据都用于训练，那么可能会<strong>对模型质量产生不利影响</strong>：模型可能会从不合理、不符合逻辑的数据中<strong>学习到不适当的规律</strong>，从而在未来的预测中产生错误的、甚至可能带来不良后果的输出；包含大量质量低下的训练样本，可能会<strong>降低整体模型的预测质量和准确性</strong>，高质量的数据可能被大量低质量数据淹没，导致模型的性能下降；如果训练数据中包含反社会、反人性的内容，这些内容可能会被模型学习并在未来的预测中体现出来，这<strong>可能导致模型的输出存在严重的偏见和歧视</strong>；模型可能过度拟合这些不合理、不符合逻辑的数据，或者具有某种特定的偏见或者偏斜的数据，从而遗忘它在更广泛、更均衡的数据上学习到的知识，导致在面对真实、合理的数据时，<strong>泛化能力受损</strong>——即使AI生成数据不包含低质量内容，如果其不能准确地反映真实世界的总体分布，那么这些数据也<strong>可能会降低模型在面对未见过任务时的泛化能力</strong>。</p><p>那么，<strong>AI模型有可能“涌现”出对生成内容质量的“品味”，找到对真实世界分布的“感觉”吗？</strong>作为一种计算模型，AI模型是通过数学运算和大量数据的训练来进行预测和决策的，并不具有真实的“感觉”或“品味”。然而，从某种程度上，AI模型可以通过学习和优化来逼近(模仿)这些功能。AI模型可以<strong>通过学习评价函数或损失函数来优化它们生成的内容质量</strong>。例如，对于语言模型，可以通过学习评估语法正确性、信息完整性、创新性等因素的评价函数来优化生成的文本质量。然而，这<strong>需要大量的标注数据和精心设计的评价函数</strong>，否则模型可能会过度优化某些容易量化的指标，而忽视其他重要的质量因素。AI模型可以<strong>通过学习真实世界数据的分布来优化其泛化能力</strong>。包括使用更大规模、更多样化的训练数据，以及使用正则化技术来防止过拟合。然而，由于真实世界的复杂性，<strong>模型可能很难完全捕捉到所有的数据分布特征，尤其是在任务不明确、数据超级稀缺的情况下</strong>。AI模型确实可以<strong>通过自监督学习方法来实现自我进化</strong>。在这种方法中，模型在没有人工标注的数据上进行训练，通过预测数据的某些部分来学习数据的结构和模式。然而，这种方法在实际应用中仍面临很多挑战，包括<strong>如何设计有效的自监督任务，如何解决模型的过拟合问题，以及如何确保模型的学习符合我们的期望和价值观等</strong>。总的来说，虽然AI模型可以在一定程度上模拟出对内容质量的“品味”和对真实世界分布的“感觉”，但它们依然<strong>依赖于我们人类设计的算法、损失函数和训练策略</strong>。未来的研究可能会发现更有效的方法来提高模型的质量判断和泛化能力，以及实现模型的自我进化。</p><p>最后，类比<strong>基因多样性</strong>的概念，也许可以更深入地理解AI训练数据的多样性和相似性对大模型质量的影响。<strong>基因多样性在生物学上是至关重要</strong>的，因为这意味着一个物种能更好地适应环境变化，增加物种的生存和繁衍能力。在AI训练中，<strong>数据多样性也同样重要</strong>。多样性丰富的数据可以提供更全面的信息，帮助AI模型学习和理解更广泛的模式和关系，提高模型的泛化能力。如果训练数据只来自AI生成的一部分，那么这些数据可能具有相似的风格和偏见，这会限制AI模型的学习和理解能力，降低其在处理新颖、未见过的任务时的表现。<strong>近亲繁殖可能导致基因的同质化</strong>，增加了有害基因的表达和累积，从而影响个体的健康和生存能力。在AI训练中，如果数据过于相似或重复，也会引起类似的问题。如果一个AI模型主要或完全使用由自身或类似模型生成的数据进行训练，那么这种<strong>“数据近亲繁殖”可能导致模型的学习过程中出现过拟合</strong>，使模型在面对新的、与训练数据不同的数据时表现不佳。此外，这种方式还可能导致模型的偏见和错误被放大，从而降低输出内容的质量。</p><p>为了<strong>避免使用AI生成数据进行训练对大模型质量的不利影响</strong>，可以从以下几个方面进行考虑：<strong>对AI生成的数据通过立法等手段在生成、分发、使用等各环节与人工数据有效区分</strong>，这是一种可能的策略，以管理和控制AI生成内容的质量和公平性，有助于提高透明度，使用户在使用这些数据时能做出知情的决定。<strong>对AI生成的数据进行筛选和质量控制</strong>，去除低质量、错误信息或者偏离真实分布的数据，确保训练数据的质量。可以采用人工或半自动的方式进行数据清洗和筛选。<strong>尽可能使用多元、多样性的数据进行训练，避免数据单一导致的过拟合</strong>，保证训练数据能够覆盖真实世界的多种情况。<strong>对模型的架构进行优化</strong>，如引入多头多层次的注意力机制，使得模型更能注意到重要的信息；<strong>对训练策略进行调整</strong>，如采用迁移学习、元学习等方法，使得模型能更好地学习和泛化；<strong>对训练过程进行监控</strong>，及时发现并纠正模型的过拟合等问题。建立<strong>有效的模型评估和反馈机制</strong>，对模型生成的结果进行质量评估，及时反馈并调整模型，<strong>形成高质量的正反馈过程</strong>，使其更好地满足质量要求。<strong>遵守相关的法规和伦理指南</strong>，保证AI的发展在可接受的道德和社会范围内。这也可以帮助确保AI生成的数据和其结果不会产生不利的影响。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;让我们从一个不那么恰当的类比开始——一个人，通过读自己原创的书稿，能受到新的启发、获得能力的提升吗？不必急着回答，因为AI大模型的学习机制，和人类的学习机制，是截然不同的。但可以肯定，至少有一点人比AI靠谱——人不会因为看自己的作品失忆、变坏、变笨，目前的AI呢，还真不一定</summary>
      
    
    
    
    <category term="随笔" scheme="https://blog.aicoco.net/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
    <category term="LLM" scheme="https://blog.aicoco.net/tags/LLM/"/>
    
  </entry>
  
  <entry>
    <title>好的代码就像一封情书</title>
    <link href="https://blog.aicoco.net/2023/07/22/good-code-like-love-letter/"/>
    <id>https://blog.aicoco.net/2023/07/22/good-code-like-love-letter/</id>
    <published>2023-07-22T01:22:11.000Z</published>
    <updated>2023-07-23T06:21:24.059Z</updated>
    
    <content type="html"><![CDATA[<p>原文：<a href="https://addyosmani.com/blog/good-code/">Good code is like a love letter to the next developer who will maintain it</a></p><h3 id="编程的真谛：好的代码是一封情书"><a href="#编程的真谛：好的代码是一封情书" class="headerlink" title="编程的真谛：好的代码是一封情书"></a>编程的真谛：好的代码是一封情书</h3><p>我们常常将编程理想化，将其描述为抽象的艺术、科学，甚至是魔法。然而，实际情况要更加务实和踏实。<strong>代码，本质上是一种沟通方式</strong>。在作者编著的《学习JavaScript设计模式》一书开篇，曾说过：“<strong>优秀的代码就像是写给将来维护它的开发者的情书</strong>。”这是一种亲密的联系，由一个开发者写给另一个开发者，跨越时间和空间。</p><h5 id="爱的语言"><a href="#爱的语言" class="headerlink" title="爱的语言"></a>爱的语言</h5><p>情书是个人的、真诚的、体贴的，是对感情的诗意见证，往往经过精心打磨，以准确地传达感情。好的代码也是如此。它是个人的，因为它反映了编写者的逻辑和方法。好的代码是真诚的，没有不必要的复杂性。它是体贴的，关心下一个开发者将如何解读它。最重要的是，好的代码经过精心设计，以最高的效率解决问题。</p><h5 id="模式和原则"><a href="#模式和原则" class="headerlink" title="模式和原则"></a>模式和原则</h5><p>就像用语法规则和语言结构可以将词语和感情组成可理解的句子，我们也有设计模式和原则来塑造代码。模式不仅使代码具有可伸缩、可维护且高效，还使其易读易懂。它们为开发者提供了共享的术语，使他们能用普遍认可的结构表达复杂的软件设计。</p><p>因此，好的代码巧妙地运用这些模式，就像熟练的诗人使用修辞手法创造共鸣。不是为了滥用模式，而是因为它们为解决方案增值，使代码更易理解，并确保代码库的持久性。</p><p>SOLID、DRY、KISS和YAGNI不仅是原则，而且是打造优秀代码的基石。它们引导开发者做出明智的决策，在过度和过少工程化之间取得平衡，最终写下让后来者珍视的“情书”。</p><h5 id="最佳实践"><a href="#最佳实践" class="headerlink" title="最佳实践"></a>最佳实践</h5><p>好的代码也遵循既定的最佳实践，就像情书会遵循某些社交礼仪一样。适当的命名约定、模块化和详尽的注释都是其中的一部分。它们不仅仅是规则，需要遵循，而且是规范，用来表明代码(或编写者)对下一个开发者是多么体贴。确保编写者的意图不会在传递中失去。</p><h5 id="拥抱测试"><a href="#拥抱测试" class="headerlink" title="拥抱测试"></a>拥抱测试</h5><p>就像作家校对他们的信件一样，开发者也应该对他们的代码进行校对。严格的测试和测试驱动开发(TDD)的实践是精心打磨的“情书”的标志。测试验证代码在各种场景下的表现，发现潜在的缺陷和盲点。强大的测试框架的存在往往证明了代码的质量。</p><h5 id="共情和尊重"><a href="#共情和尊重" class="headerlink" title="共情和尊重"></a>共情和尊重</h5><p>最重要的是，一篇情书的核心是对读者的共情和尊重，好的代码也是如此。编写其他人可以阅读、理解和维护的代码，是一种职业尊重。这表明编写者理解他们的工作是一个更大的、持续不断的努力，软件是一个不断演进的生命体，将有许多人在未来继续塑造它，续写它的命运。</p><h5 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h5><p>最后，编程是一种创作行为，类似于写一首诗或画一幅画。然而，我们的创作之美不仅仅取决于我们算法的优雅或代码的高效，更取决于其他人可以如何快乐、轻松地在我们打下的基础上继续展开工作。作为开发者，我们的任务不仅是解决今天的问题，也是确保我们不会成为明天的问题。</p><p>因此，好的代码不仅是一封情书，也是我们留给后来者永恒的遗产。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;原文：&lt;a href=&quot;https://addyosmani.com/blog/good-code/&quot;&gt;Good code is like a love letter to the next developer who will maintain it&lt;/a&gt;&lt;/p&gt;
&lt;h</summary>
      
    
    
    
    <category term="文摘" scheme="https://blog.aicoco.net/categories/%E6%96%87%E6%91%98/"/>
    
    
    <category term="Programming" scheme="https://blog.aicoco.net/tags/Programming/"/>
    
  </entry>
  
  <entry>
    <title>LLaMA2不是真正意义上的“开源”</title>
    <link href="https://blog.aicoco.net/2023/07/22/llama2-isnt-open-source/"/>
    <id>https://blog.aicoco.net/2023/07/22/llama2-isnt-open-source/</id>
    <published>2023-07-22T01:09:12.000Z</published>
    <updated>2023-07-23T06:16:54.294Z</updated>
    
    <content type="html"><![CDATA[<p>原文：<a href="https://www.alessiofanelli.com/blog/llama2-isnt-open-source">LLaMA2 isn’t “Open Source” - and why it doesn’t matter</a></p><h3 id="LLaMA2-并非真正的“开源”，但这并不重要"><a href="#LLaMA2-并非真正的“开源”，但这并不重要" class="headerlink" title="LLaMA2 并非真正的“开源”，但这并不重要"></a>LLaMA2 并非真正的“开源”，但这并不重要</h3><p>作者是一位开源公司创始人，多年来一直参与开源社区，对开源项目的贡献、演讲和投资充满热情。他认为，互联网之所以成为现在的样子，很大程度上归功于那些支撑着数字基础设施的优秀开源项目，因此开源始终是他心中的重要话题。</p><p>然而，当 LLaMA2 出现时，许多他尊敬的社区成员对该模型误用“开源”一词感到不满。</p><p>LLaMA2 虽然在很大程度上是开源的，但其中有限制条件，例如：如果在发布日期时月活跃用户超过7亿，就不能以商业目的使用该模型；同时也不能使用该模型的输出结果来训练其他大型语言模型。这些限制与开源精神不太相符。但是，尽管作者同意 LLaMA2 在传统意义上不能称为开源，但他认为这并不重要。在人工智能模型的世界中，“开源”一词需要再次演变。</p><h5 id="从自由到开源"><a href="#从自由到开源" class="headerlink" title="从自由到开源"></a>从自由到开源</h5><p>在文章中，作者回顾了自由软件和开源运动的历史。自1976年“给业余爱好者的公开信”以来，软件公司的商业利益与想要绕过限制的黑客的好奇心之间一直存在紧张关系。70年代，自由软件运动在麻省理工学院的人工智能实验室起源，由 Richard Stallman 创立，最终于1983年发展成 GNU 项目。GPL “copyleft” 许可证诞生，并被 Red Hat、MySQL、Git 和 Ubuntu 等项目采用。</p><p>“开源”这个词在1998年得以确立，归功于麻省理工学院的 Christine Peterson。在“免费软件高峰会”上，“自由软件”一词正式被“开源软件”取代。随着时间的推移，“自由软件”和“开源软件”社区出现了分歧，因为它们对“自由”和“开源”的理解不同。自由软件，如自由软件基金会所规定，只是开源软件的一个子集，采用非常宽松的许可证，如 GPL 和 Apache。</p><p>在过去十年里，由于商业开源公司和云超大规模企业之间的紧张关系，出现了另一种分歧。Elastic 和 MongoDB 将其开源项目转换为“服务器端公共许可证”（SSPL），允许开发者在商业用途下使用产品，前提是所提供的不是产品的托管版本。其目标是阻止 AWS 将它们的产品作为云服务重新托管并从中获利。然而，SSPL 也侵犯了开源理念，并未获得开源倡议组织的认可。尽管如此，大多数开发者仍然认为 MongoDB 是开源的。逐渐地，“开源”一词正在失去其自由的涵义，在开发者心目中几乎成为“源码可用”的同义词。</p><h5 id="从源码到权重"><a href="#从源码到权重" class="headerlink" title="从源码到权重"></a>从源码到权重</h5><p>随着像 Dolly、MPT、LLaMA 等开放模型的崛起，社区中出现了类似的分歧。对于大多数 AI 工程师来说，如今的“开源”意味着“可下载权重”，仅此而已。Heather Meeker 提出了“开放权重”的定义，但目前还没有社区共识。问题在于，开放权重是否足以使一个模型被称为开源；软件的类比是项目发布其二进制文件而不提供源代码以供重新构建。</p><p>要使模型真正成为开源且可从头开始重新训练，创建者需要分享所有的训练代码、预训练数据集、微调偏好、RLHF 示例等。然而，这些训练过程的成本非常高，即使有人愿意全部公开，对于大多数开发者和公司来说，从头训练模型是不可行的，因此能够获得最终权重更加实用。</p><h5 id="开放模型"><a href="#开放模型" class="headerlink" title="开放模型"></a>开放模型</h5><p>在大型语言模型（LLMs）领域，术语“开源”用于定义多种开放程度：</p><ol><li>开放模型：如 RedPajama 和 MPT-7B，它们的权重对商业用途是开放的（使用 Apache 2.0 许可证），而且可以从头开始重新训练，因为数据集是开源的。</li><li>开放权重：StableLM 是 StabilityAI 训练的开放模型。权重是开放的，使用 Apache 2.0 许可证，但用于训练的数据集对公众是不可用的。</li><li>受限权重：这是指 LLaMA2。预训练数据集也不可用，尽管权重据称对商业用途是开放的，但存在上述特定限制。</li><li>受污染(Contaminated)权重：Dolly 1.0 和 LLaMA1 属于这一类别。权重是公开的，但用于训练它们的数据集不允许商业用途，这使得它在技术上是开放的，但实际上是无用的。</li></ol><p>在可预见的未来，开源和开放权重将被互换使用，而作者认为这没问题。重要的是，越来越多的工作以尽可能开放的方式进行。对于 LLaMA2 的许可证，人们可能感到失望，但是 Meta 刚刚将价值约200万美元的浮点运算放进了 Github 库，作者认为这对该领域的进展将产生积极的影响。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;原文：&lt;a href=&quot;https://www.alessiofanelli.com/blog/llama2-isnt-open-source&quot;&gt;LLaMA2 isn’t “Open Source” - and why it doesn’t matter&lt;/a&gt;&lt;/p&gt;
&lt;</summary>
      
    
    
    
    <category term="文摘" scheme="https://blog.aicoco.net/categories/%E6%96%87%E6%91%98/"/>
    
    
    <category term="LLM" scheme="https://blog.aicoco.net/tags/LLM/"/>
    
  </entry>
  
  <entry>
    <title>Meta为何选择开源Llama 2？</title>
    <link href="https://blog.aicoco.net/2023/07/22/why-did-meta-open-source-llama/"/>
    <id>https://blog.aicoco.net/2023/07/22/why-did-meta-open-source-llama/</id>
    <published>2023-07-22T00:40:27.000Z</published>
    <updated>2023-07-23T06:20:35.727Z</updated>
    
    <content type="html"><![CDATA[<p>原文：<a href="https://matt-rickard.com/why-did-meta-open-source-llama">Why Did Meta Open-Source Llama 2?</a></p><h4 id="对Meta开源Llama-2可能原因的一些猜想"><a href="#对Meta开源Llama-2可能原因的一些猜想" class="headerlink" title="对Meta开源Llama 2可能原因的一些猜想"></a>对Meta开源Llama 2可能原因的一些猜想</h4><h5 id="削弱竞争对手的优势"><a href="#削弱竞争对手的优势" class="headerlink" title="削弱竞争对手的优势"></a>削弱竞争对手的优势</h5><ul><li><p>Llama 2 对拥有专有模型的竞争对手，如Google和OpenAI(以及Microsoft的相关服务)，构成了挑战。通过开源大模型，可以<strong>削弱这些大公司在语言模型领域的优势</strong>。</p></li><li><p>作为身处服务栈需要<strong>持续吸引用户</strong>的公司，Meta坐拥数十亿固定用户，这使他们在竞争中占据优势。</p></li></ul><h5 id="市场推广策略的考虑"><a href="#市场推广策略的考虑" class="headerlink" title="市场推广策略的考虑"></a>市场推广策略的考虑</h5><ul><li><p>Llama 2提供不同参数大小的模型，包括7b、13b和70b。通过将较小的模型作为“免费版”自助选项，Meta可以吸引用户，并鼓励他们在未来<strong>选择Meta平台的更大或更新的版本</strong>。</p></li><li><p>Meta可能推出一系列与Llama 2<strong>相关的扩展产品</strong>，包括为Instagram、Threads或Facebook提供支持Llama的功能，特殊设计的硬件芯片和数据中心，以及在PyTorch中优化Llama衍生模型的机器学习框架。</p></li><li><p>此外，Meta未来可能推出<strong>托管服务作为商业化产品</strong>，其中将Llama 2作为基础组件。</p></li></ul><h5 id="市场营销和声誉建设"><a href="#市场营销和声誉建设" class="headerlink" title="市场营销和声誉建设"></a>市场营销和声誉建设</h5><ul><li>通过开源Llama 2并将自己定位为技术前沿的公司，Meta旨在<strong>建立强大的声誉</strong>。这样的声誉可以吸引开发者、用户和媒体的关注，类似于Google多年来的积极影响。</li></ul><p>总体而言，开源Llama 2的决定使得Meta可以挑战和削弱竞争对手，用自助免费模型吸引用户，在语言模型领域树立创新领先的公司形象。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;原文：&lt;a href=&quot;https://matt-rickard.com/why-did-meta-open-source-llama&quot;&gt;Why Did Meta Open-Source Llama 2?&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&quot;对Meta开源Llama-2可能原因</summary>
      
    
    
    
    <category term="文摘" scheme="https://blog.aicoco.net/categories/%E6%96%87%E6%91%98/"/>
    
    
    <category term="LLM" scheme="https://blog.aicoco.net/tags/LLM/"/>
    
  </entry>
  
  <entry>
    <title>沉迷工具不会让你成为大师</title>
    <link href="https://blog.aicoco.net/2023/07/10/Amateurs-obsess-over-tools-pros-over-mastery/"/>
    <id>https://blog.aicoco.net/2023/07/10/Amateurs-obsess-over-tools-pros-over-mastery/</id>
    <published>2023-07-10T03:21:09.000Z</published>
    <updated>2023-07-23T06:29:28.813Z</updated>
    
    <content type="html"><![CDATA[<p>原文：<a href="https://adamsinger.substack.com/p/amateurs-obsess-over-tools-pros-over">Amateurs obsess over tools, pros over mastery</a></p><h4 id="文章主要信息"><a href="#文章主要信息" class="headerlink" title="文章主要信息"></a>文章主要信息</h4><ul><li>文章强调了业余爱好者过度迷恋新工具，而专业人士更关注技艺的精湛。</li><li>专业人士知道工具并不能决定成就，真正重要的是个人运用它们的心态和技能。</li><li>文章通过例子阐述了技能的重要性，指出工具本身并非关键，个人的精湛运用才是决定成就的关键。</li><li>文章提倡专注于培养基本技能和永恒的原则，摒弃追求新奇工具的心态。</li></ul><h4 id="详细重点内容"><a href="#详细重点内容" class="headerlink" title="详细重点内容"></a>详细重点内容</h4><ol><li><p><strong>业余爱好者迷恋新工具</strong>：现代科技发展迅速，新的工具和应用层出不穷。很多人容易陷入追逐新工具的陷阱，相信使用这些工具会带来高效率、更多产出和成功。然而，过度迷恋新工具只是短暂的热情，很快就会被其他新工具取代，而这些追逐也是徒劳的。</p></li><li><p><strong>专业人士关注技艺</strong>：与业余爱好者不同，真正的专业人士知道工具并不能代表他们的成就。他们理解重要的是运用这些工具的个人心态和技能。类似于音乐家运用吉他演奏，吉他本身可能并不是最先进的工具，但在熟练的音乐家手中，它能产生动人的旋律和感人的和声。</p></li><li><p><strong>精湛的技艺超越工具</strong>：文章举例说明吉他手通过对技艺的深入研究和练习，使得吉他成为创作灵感的源泉。这表明真正的精湛技艺超越了工具本身，是在不受技术潮流影响的基础上持续存在的。</p></li><li><p><strong>专注培养基本技能</strong>：专业人士理解重要的是不断磨练自己的技艺，无论手中有怎样的工具。文章引用了武术家李小龙的名言，强调通过深入、持续的练习，掌握基本技能才是成为专家的关键。</p></li><li><p><strong>不盲目追求新工具</strong>：文章警示不要盲目追求新工具，而是专注于打磨自己的技能。新工具可能只是短暂的潮流，而真正持久的是对基本技能和原则的坚持。</p></li><li><p><strong>超越人工智能的创造力</strong>：文章提到人工智能的发展，但也指出真正的创造力和技艺仍然超越人工智能的能力。专注于个人的技艺将使人们摆脱对人工智能创造力的过度依赖，实现真正意义上的创新。</p></li><li><p><strong>反思和自省</strong>：文章最后呼吁读者在追逐新工具时停下来反思，问自己是否真正在提升自己的技艺，是否被他人的意见所左右，是否在做真正有意义的事情，而不是只是追逐表面的诱惑。</p></li></ol><h4 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h4><p>文章强调了专业人士不是盲目追求新工具，而是注重培养自己的技艺和技能。真正的精湛技艺超越了工具本身，并且在不受技术潮流影响的基础上持续存在。专注于培养基本技能和原则，而不是追逐新奇工具，才能成为真正的专业人士。文章还提醒我们要超越人工智能的创造力，通过反思和自省，避免陷入盲目追逐的状态。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;原文：&lt;a href=&quot;https://adamsinger.substack.com/p/amateurs-obsess-over-tools-pros-over&quot;&gt;Amateurs obsess over tools, pros over mastery&lt;/a&gt;&lt;/p&gt;</summary>
      
    
    
    
    <category term="文摘" scheme="https://blog.aicoco.net/categories/%E6%96%87%E6%91%98/"/>
    
    
  </entry>
  
  <entry>
    <title>AI权重开&quot;源&quot;怎么论</title>
    <link href="https://blog.aicoco.net/2023/07/06/AI_weights_are_not_open_source/"/>
    <id>https://blog.aicoco.net/2023/07/06/AI_weights_are_not_open_source/</id>
    <published>2023-07-06T11:17:38.000Z</published>
    <updated>2023-07-23T06:33:50.418Z</updated>
    
    <content type="html"><![CDATA[<p>原文：<a href="https://opencoreventures.com/blog/2023-06-27-ai-weights-are-not-open-source/">AI weights are not open “source”</a></p><h4 id="文章主要信息总结"><a href="#文章主要信息总结" class="headerlink" title="文章主要信息总结"></a>文章主要信息总结</h4><ul><li>AI的许可证复杂多样，不同于传统软件的开源或专有授权。</li><li>AI有多个组成部分，如源码、权重、数据等，每个部分的许可方式可能不同。</li><li>为了标准化对AI许可证的讨论，文章提出了一套许可证类型的分类，包括专有、合作者、可用、伦理和开源。</li><li>提倡区分AI的源代码和权重，认识到权重不是源代码，需要特定的许可证类型。</li><li>引用了“开放权重”（Open Weights）和“伦理权重”（Ethical Weights）等术语，以便更准确地描述不同类型的AI权重许可证，避免误用“开源”这个术语。</li></ul><h4 id="详细重点内容"><a href="#详细重点内容" class="headerlink" title="详细重点内容"></a>详细重点内容</h4><ol><li><p><strong>AI许可证复杂性</strong>：AI许可证不同于传统的软件许可证，因为AI有多个组成部分，如源码、权重、数据等，每个部分可能有不同的许可方式。此外，AI的使用还涉及到社会伦理层面的考量，需要更多的限制和约束。</p></li><li><p><strong>标准化许可证分类</strong>：为了更好地讨论AI许可证，文章提出了一套分类，包括专有、合作者、可用、伦理和开源。每个分类针对不同的用途和组成部分，以更清晰地描述许可证的属性。</p></li><li><p><strong>“开放权重”和“伦理权重”</strong>：文章指出权重和源代码是两个不同的概念，不能将权重称为“开源”，因为它们并不是源代码。为了避免混淆，文章提出了“开放权重”和“伦理权重”等术语，以更准确地描述权重的开放程度和许可限制。</p></li><li><p><strong>权重的真正开放性</strong>：许多标注为“开源”的AI权重实际上并不是真正的开源，因为它们不是源代码，而是特定的组件。文章强调使用正确的术语，如“开放权重”和“伦理权重”，有助于推动行业发展，并在不同类型的权重上建立标准。</p></li><li><p><strong>避免“开源洗白”</strong>：由于AI面临与传统软件不同的挑战，可能需要限制某些潜在的有害用途。文章提倡使用“伦理”来描述允许类似开源的自由使用的许可证，避免“开源洗白”，为用户提供更清晰的信息。</p></li></ol><h4 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h4><p>文章着重强调AI许可证的复杂性，提出了一套分类以标准化对AI许可证的讨论。作者建议使用“开放权重”和“伦理权重”等术语，以更准确地描述不同类型的AI权重许可证，避免混淆和误用“开源”这个术语。同时，文章强调区分AI的源代码和权重，认识到权重不是源代码，需要特定的许可证类型。通过正确的命名和分类，有助于推动AI领域的标准化和发展。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;原文：&lt;a href=&quot;https://opencoreventures.com/blog/2023-06-27-ai-weights-are-not-open-source/&quot;&gt;AI weights are not open “source”&lt;/a&gt;&lt;/p&gt;
&lt;h4 id</summary>
      
    
    
    
    <category term="文摘" scheme="https://blog.aicoco.net/categories/%E6%96%87%E6%91%98/"/>
    
    
    <category term="LLM" scheme="https://blog.aicoco.net/tags/LLM/"/>
    
  </entry>
  
  <entry>
    <title>AIGC时代程序员如何保持领先</title>
    <link href="https://blog.aicoco.net/2023/07/05/4_tips_for_programmers_to_stay_ahead_of_generative_AI/"/>
    <id>https://blog.aicoco.net/2023/07/05/4_tips_for_programmers_to_stay_ahead_of_generative_AI/</id>
    <published>2023-07-05T13:22:38.000Z</published>
    <updated>2023-07-23T06:37:27.873Z</updated>
    
    <content type="html"><![CDATA[<p>原文：<a href="https://spectrum.ieee.org/ai-programming">How Coders Can Survive—and Thrive—in a ChatGPT World &gt; 4 tips for programmers to stay ahead of generative AI</a></p><h4 id="文章主要信息总结"><a href="#文章主要信息总结" class="headerlink" title="文章主要信息总结"></a>文章主要信息总结</h4><ul><li>人工智能，特别是由大型语言模型（LLM）驱动的生成式人工智能，可能会改变许多编程人员的生计，但一些专家认为AI不会立即取代人类程序员。</li><li>软件开发人员可以通过遵循基本原则和最佳实践，以及找到适合自己需求的AI工具来在生成式AI时代生存和发展。</li><li>保持对编程基础和问题解决技能的重视，同时加强软件工程实践，规划系统设计和软件架构。</li><li>在使用AI编程助手时，清晰明确的交流是关键，需要详细说明需求，使用合适的提示工程方法，对AI生成的代码进行审查和验证。</li><li>开发人员应对大型语言模型的输出持批判态度，了解其潜在的风险和局限性，同时注意版权和安全问题。</li></ul><h4 id="详细重点内容"><a href="#详细重点内容" class="headerlink" title="详细重点内容"></a>详细重点内容</h4><ol><li><p><strong>保持基本原则和最佳实践</strong>：虽然AI辅助编码工具可以帮助完成代码和生成代码，但编程的基本原则和最佳实践依然重要，如阅读和理解自己和他人的代码，以及了解编写的代码如何适应更大的系统。</p></li><li><p><strong>问题解决技能</strong>：解决问题仍然是程序员最重要的技能之一。分析问题并找到优雅的解决方案在编程领域中依然备受推崇。</p></li><li><p><strong>选择适合自己需求的AI工具</strong>：找到合适的AI工具至关重要。不同的工具有不同的交互方式和整合方式，可以用于自动化单元测试的创建、生成测试数据、或编写文档等。</p></li><li><p><strong>清晰明确的交流</strong>：使用AI编程助手时，需要详细说明需求，对生成的代码进行审查和验证。合理的提示工程方法可以帮助与AI模型进行更有效的交流，以获取满足需求的代码。</p></li><li><p><strong>对AI输出持批判态度</strong>：大型语言模型往往会产生错误或不准确的代码，因此软件工程师需要对生成的代码进行审查和验证。了解模型的训练数据和版本等信息有助于理解结果并提供更多上下文。</p></li><li><p><strong>注意安全和版权问题</strong>：AI生成的代码可能存在漏洞，软件工程师需要注意安全问题，并采取代码审查和强有力的测试流程来防范风险。此外，版权问题也需要考虑，尤其是使用私有代码时。</p></li></ol><h4 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h4><p>在生成式AI时代，软件开发人员需要认识到AI是一种工具，将其纳入工作流程，同时了解这些工具的机会和限制，并继续依靠自己的人类编码能力来取得成功。重视问题解决能力、保持软件工程实践和审查AI输出是软件开发人员在AI时代生存和发展的关键。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;原文：&lt;a href=&quot;https://spectrum.ieee.org/ai-programming&quot;&gt;How Coders Can Survive—and Thrive—in a ChatGPT World &amp;gt; 4 tips for programmers to</summary>
      
    
    
    
    <category term="文摘" scheme="https://blog.aicoco.net/categories/%E6%96%87%E6%91%98/"/>
    
    
    <category term="AIGC" scheme="https://blog.aicoco.net/tags/AIGC/"/>
    
  </entry>
  
  <entry>
    <title>科研数据分享最佳实践</title>
    <link href="https://blog.aicoco.net/2023/06/29/How-to-make-your-scientific-data-accessible-discoverable-and-useful/"/>
    <id>https://blog.aicoco.net/2023/06/29/How-to-make-your-scientific-data-accessible-discoverable-and-useful/</id>
    <published>2023-06-29T02:57:33.000Z</published>
    <updated>2023-07-23T06:39:21.029Z</updated>
    
    <content type="html"><![CDATA[<p>原文：<a href="https://www.nature.com/articles/d41586-023-01929-7">How to make your scientific data accessible, discoverable and useful</a></p><p>这篇文章讨论了在开放科学和可重复性的背景下发布可用和高质量数据的最佳实践。越来越多的研究人员被鼓励在发表论文的同时提交数据，但在处理来自不同来源和格式的数据时可能会遇到挑战。以下是一些数据科学家建议的关键做法：</p><ol><li><p><strong>制定元数据</strong>: 元数据描述数据，对于使数据符合FAIR（可找到、可访问、可互操作、可重用）原则至关重要。科学家应提供详细的数据收集、处理和变量信息，以及表格或文件之间相互关联的解释。</p></li><li><p><strong>多分享</strong>: 最好能同时分享原始数据和派生数据。原始数据允许其他研究人员测试假设和处理策略，而派生数据则是分析的基础。</p></li><li><p><strong>采纳标准</strong>: 科学家应该寻求更广泛社区的指导，了解数据存储库和文件格式。推荐使用开放、非专有的文件格式，如CSV，以确保数据长期可读。</p></li><li><p><strong>包含代码</strong>: 当数据分析涉及代码时，研究人员应将代码与数据一起分享。代码应有良好的文档记录，清除特定计算机元素，并经过可重现性测试。</p></li><li><p><strong>考虑可访问性</strong>: 考虑潜在数据用户的技术基础设施和要求。咨询相关组织，以获取有关数据标准和假设的反馈，并为不同条件下的用户开发低技术解决方案。</p></li><li><p><strong>迈出第一步</strong>: 开放科学不必是非此即彼的。即使分享部分数据也能增加价值和促进合作机会。</p></li></ol><p>通过遵循这些最佳实践，研究人员可以促进科学的发展，推动合作，并确保其工作的可重复性。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;原文：&lt;a href=&quot;https://www.nature.com/articles/d41586-023-01929-7&quot;&gt;How to make your scientific data accessible, discoverable and useful&lt;/a&gt;&lt;</summary>
      
    
    
    
    <category term="文摘" scheme="https://blog.aicoco.net/categories/%E6%96%87%E6%91%98/"/>
    
    
    <category term="Academic" scheme="https://blog.aicoco.net/tags/Academic/"/>
    
    <category term="Data" scheme="https://blog.aicoco.net/tags/Data/"/>
    
  </entry>
  
</feed>

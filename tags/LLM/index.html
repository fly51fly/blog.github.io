<!DOCTYPE html>
<html lang='zh-CN'>

<head>
  <meta name="generator" content="Hexo 6.3.0">
  <meta name="hexo-theme" content="https://github.com/xaoxuu/hexo-theme-stellar/tree/1.19.0">
  <meta charset="utf-8">
  <meta name="robots" content="noindex,follow">

  <meta http-equiv='x-dns-prefetch-control' content='on' />
  <link rel='dns-prefetch' href='https://gcore.jsdelivr.net'>
  <link rel="preconnect" href="https://gcore.jsdelivr.net" crossorigin>
  <link rel='dns-prefetch' href='//unpkg.com'>

  <meta name="renderer" content="webkit">
  <meta name="force-rendering" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
  <meta name="HandheldFriendly" content="True" >
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="theme-color" content="#f8f8f8">
  <meta name="google-site-verification" content="uXzWaSqct7cieDPaX4gdDWaAlWkiYxHTYVdt4TsQElc" />
  
  <title>标签：LLM - 爱可可小窝</title>

  
    <meta name="description" content="fly51fly的个人博客">
<meta property="og:type" content="website">
<meta property="og:title" content="爱可可小窝">
<meta property="og:url" content="https://blog.aicoco.net/tags/LLM/index.html">
<meta property="og:site_name" content="爱可可小窝">
<meta property="og:description" content="fly51fly的个人博客">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Guang Chen">
<meta name="twitter:card" content="summary">
<meta name="twitter:creator" content="@fly51fly">
  
  
  
  

  <!-- feed -->
  
    <link rel="alternate" href="/atom.xml" title="爱可可小窝" type="application/atom+xml">
  

  
    
<link rel="stylesheet" href="/css/main.css">

  

  

  

  


  
    
      <link rel="stylesheet" href="https://upyun.thatcdn.cn/hexo/stellar/css/font.css">
    
  
</head>

<body>
  


  <div class='l_body' id='start'>
    <aside class='l_left' layout=''>
    

  

<header class="header"><div class="logo-wrap"><a class="title" href="/"><div class="main" ff="title">爱可可小窝</div><div class="sub cap">@爱可可-爱生活 的学习与思考</div></a></div>

<nav class="menu dis-select"></nav>
</header>


<div class="widgets">
<widget class="widget-wrapper search"><div class="widget-body"><div class="search-wrapper" id="search"><form class="search-form"><input type="text" class="search-input" id="search-input" data-filter="/blog/" placeholder="文章搜索"><svg t="1670596976048" class="icon search-icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="2676" width="200" height="200"><path d="M938.2 832.6L723.8 618.1c-2.5-2.5-5.3-4.4-7.9-6.4 36.2-55.6 57.3-121.8 57.3-193.1C773.3 222.8 614.6 64 418.7 64S64 222.8 64 418.6c0 195.9 158.8 354.6 354.6 354.6 71.3 0 137.5-21.2 193.2-57.4 2 2.7 3.9 5.4 6.3 7.8L832.5 938c14.6 14.6 33.7 21.9 52.8 21.9 19.1 0 38.2-7.3 52.8-21.8 29.2-29.1 29.2-76.4 0.1-105.5M418.7 661.3C284.9 661.3 176 552.4 176 418.6 176 284.9 284.9 176 418.7 176c133.8 0 242.6 108.9 242.6 242.7 0 133.7-108.9 242.6-242.6 242.6" p-id="2677"></path></svg></form><div id="search-result"></div><div class="search-no-result">没有找到内容！</div></div></div></widget>

<widget class="widget-wrapper recent"><div class="widget-header cap theme dis-select"><span class="name">最近更新</span></div><div class="widget-body related-posts fs14"><a class="item title" href="/2023/08/14/open-source-llm-not-open/"><span class="title">Llama和ChatGPT都不算开源</span></a><a class="item title" href="/2023/08/09/does-one-model-rule-them-all/"><span class="title">单一大模型能包打天下吗？</span></a><a class="item title" href="/2023/08/08/grokking/"><span class="title">机器学习模型的grokking是记忆还是泛化？</span></a><a class="item title" href="/2023/08/07/the-floss-transition/"><span class="title">面临转型的免费开源软件</span></a><a class="item title" href="/2023/08/06/llm-patterns/"><span class="title">大型语言模型系统和产品的构建模式</span></a></div></widget>


</div>


    </aside>
    <div class='l_main list'>
      
  

<header class="header mobile-only"><div class="logo-wrap"><a class="title" href="/"><div class="main" ff="title">爱可可小窝</div><div class="sub cap">@爱可可-爱生活 的学习与思考</div></a></div></header>



      

  


  

<div class="nav-wrap"><nav class="sub post cap"><a href="/">近期发布</a><a href="/categories">分类</a><a class="active" href="/tags">标签：LLM</a><a href="/archives">归档</a></nav></div>

  <div class="post-list post"><a class="post-card post " href="/2023/08/14/open-source-llm-not-open/">
<article class="md-text"><div class="post-cover"><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="/images/open-source-llm-not-open.jpg"/></div><h2 class="post-title">Llama和ChatGPT都不算开源</h2><div class="excerpt"><p>原文：Llama and ChatGPT Are Not Open-Source
文章分析了Meta发布的LLM模型Llama 2和OpenAI的ChatGPT是否真正开源。使用Radboud大学研究员设计的一套标准来给不同开源LLM模型的开放程度进行评分。论文指出，虽然Meta提供了Llama 2的预训练模型权重和文档，但未公开训练数据和训练代码，也未进行同行评审。进一步比较不同模型，论文...</p></div><div class="meta cap"><span class="cap" id="post-meta">发布于&nbsp;<time datetime="2023-08-14T00:55:00.000Z">2023-08-14</time></span><span class="cap breadcrumb">文摘</span></div></article>
</a><a class="post-card post " href="/2023/08/09/does-one-model-rule-them-all/">
<article class="md-text"><div class="post-cover"><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="/images/does-one-model-rule-them-all.jpg"/></div><h2 class="post-title">单一大模型能包打天下吗？</h2><div class="excerpt"><p>原文：Does One Large Model Rule Them All?
文章探讨了人工智能的未来，提出一个观点：单一的大型通用人工智能模型不会主导整个人工智能生态系统。
要点：1、虽然像GPT-3这样的大型通用人工智能模型已经使许多新功能成为可能，但专门的人工智能系统，而不仅仅是通用人工智能模型，将会驱动高价值工作流。2、在高价值工作流中，专门化对于质量保证至关重要。融入用户反馈需要对...</p></div><div class="meta cap"><span class="cap" id="post-meta">发布于&nbsp;<time datetime="2023-08-09T00:22:36.000Z">2023-08-09</time></span><span class="cap breadcrumb">文摘</span></div></article>
</a><a class="post-card post " href="/2023/08/06/can-you-simply-brainwash-an-llm/">
<article class="md-text"><div class="post-cover"><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="/images/can-you-simply-brainwash-an-llm.jpg"/></div><h2 class="post-title">给 LLM 洗脑能行吗？</h2><div class="excerpt"><p>原文：Can you simply brainwash an LLM?
文章的主题是关于大型语言模型（LLM）的可追溯性和潜在的供应链问题。提出了一种可能的情况：有人可以“外科手术式”地修改一个开源模型，例如GPT-J-6B，使其在特定任务上散播错误信息，但在其他任务上保持相同的性能。然后，可以将其分发到Hugging Face，以展示LLM的供应链可能如何遭到破坏。
要点：  

语言模型...</p></div><div class="meta cap"><span class="cap" id="post-meta">发布于&nbsp;<time datetime="2023-08-06T11:48:28.000Z">2023-08-06</time></span><span class="cap breadcrumb">文摘</span></div></article>
</a><a class="post-card post " href="/2023/08/06/llm-patterns/">
<article class="md-text"><div class="post-cover"><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="/images/llm-patterns.jpg"/></div><h2 class="post-title">大型语言模型系统和产品的构建模式</h2><div class="excerpt"><p>原文：Patterns for Building LLM-based Systems &amp; Products
标题: 大型语言模型（LLM）系统和产品的构建模式
要点:

讨论了将大型语言模型（LLM）集成到系统和产品中的实用模式，包括学术研究、行业资源和实践者的知识，并将它们提炼为关键的思想和实践。  
介绍了七个关键模式，包括：Evals（性能评估）、RAG（添加最新的外部知识）、...</p></div><div class="meta cap"><span class="cap" id="post-meta">发布于&nbsp;<time datetime="2023-08-06T10:33:57.000Z">2023-08-06</time></span><span class="cap breadcrumb">文摘</span></div></article>
</a><a class="post-card post " href="/2023/08/06/llm-vs-oss/">
<article class="md-text"><div class="post-cover"><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="/images/llm_vs_oss.jpg"/></div><h2 class="post-title">大语言模型开源的利与弊</h2><div class="excerpt"><p>先对以大型语言模型(LLM)为代表的大模型的开源和代码项目的开源做个简单比较：




大模型的开源
代码项目的开源



开放内容
预训练的模型，主要是网络结构和参数，一般不开放训练数据和训练代码（以及训练过程&amp;技巧）。
为实现特定功能或应用编写的代码或脚本。


潜在风险
可能输出有偏见、不准确或误导性信息；存在滥用风险，用于钓鱼、恶意软件编写等。
可能存在漏洞或错误，被恶意利用...</p></div><div class="meta cap"><span class="cap" id="post-meta">发布于&nbsp;<time datetime="2023-08-06T01:00:32.000Z">2023-08-06</time></span><span class="cap breadcrumb">随笔</span></div></article>
</a><a class="post-card post " href="/2023/07/24/teach-your-llm-vector-sql/">
<article class="md-text"><div class="post-cover"><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="/images/teach-your-llm-vector-sql.jpg"/></div><h2 class="post-title">让LLM总是用事实而不是虚构来回答问题</h2><div class="excerpt"><p>原文：Teach your LLM to always answer with facts not fiction
LLM幻觉与使用Vector SQL减少幻觉主要信息
LLM（Large Language Model）是一种高级AI系统，可以回答广泛范围的问题，但在陌生话题上可能出现幻觉现象。
幻觉是指在缺乏外部刺激的情况下，产生具有真实感知质量的感知错误。
增加外部知识可以减少LLM幻觉...</p></div><div class="meta cap"><span class="cap" id="post-meta">发布于&nbsp;<time datetime="2023-07-24T13:08:31.000Z">2023-07-24</time></span><span class="cap breadcrumb">文摘</span></div></article>
</a><a class="post-card post " href="/2023/07/23/differences-between-human-and-ai/">
<article class="md-text"><div class="post-cover"><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://s1.ax1x.com/2023/07/23/pCq7gPg.md.jpg"/></div><h2 class="post-title">人和大模型之间最大的差距</h2><div class="excerpt"><p>非常认同Andrej Kalpathy在“State of GPT”报告里分享的观点（以下为宝玉搬运字幕版，中文翻译质量很高），结合我的思考进一步阐述如下：
微软2003年Build大会演讲：如何训练和应用GPT
人和大模型之间最大的差距，在于思考过程和追求答案的方向。
人有内心独白，会调动经验，拆解问题，进行复杂的思考过程，追求合理、准确的答案，注重答案从内容到形式的“优雅”，即我们常说的...</p></div><div class="meta cap"><span class="cap" id="post-meta">发布于&nbsp;<time datetime="2023-07-23T06:55:53.000Z">2023-07-23</time></span><span class="cap breadcrumb">随笔</span></div></article>
</a><a class="post-card post " href="/2023/07/23/effects-of-more-params/">
<article class="md-text"><div class="post-cover"><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://s1.ax1x.com/2023/07/23/pCqooyq.md.jpg"/></div><h2 class="post-title">大模型参数规模越大越好吗？</h2><div class="excerpt"><p>先说结论：规模是把双刃剑，平衡点需具体权衡。
从大模型记忆论的观点来看，模型规模越大，参数越多，记忆容量越高，对整体数据分布的把握就越全面，可以增加模型在推理时的工作记忆，生成更具创新性、更多样的结果。但与此同时，随着熵增，高概率候选结果的多样化会呈指数级爆发，这就带来了一个挑战：如何在这些结果中进行优选，使得模型的输出与人类的价值观对齐。
从大模型压缩论的观点来看，大模型的目标是通过压缩世...</p></div><div class="meta cap"><span class="cap" id="post-meta">发布于&nbsp;<time datetime="2023-07-23T06:50:16.000Z">2023-07-23</time></span><span class="cap breadcrumb">随笔</span></div></article>
</a><a class="post-card post " href="/2023/07/23/can-ai-displace-doctor/">
<article class="md-text"><div class="post-cover"><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://s1.ax1x.com/2023/07/23/pCqorQI.md.jpg"/></div><h2 class="post-title">医疗AI会取代人类医生吗？</h2><div class="excerpt"><p>医疗除了技术问题以外，也许更重要的，会涉及对人类情感的理解和关怀。尽管AI能处理大量数据，但其在理解人类情绪和个体经历方面有限。这对处理如慢性病管理和心理健康问题等多元健康问题显得尤为重要。
每个病人都是独特的，需要全面、个性化和富有同情心的医疗服务，也就是个性化的诊疗服务。尽管AI能有效处理和分析大量信息，但其决策基于已有数据和已知规则，对新颖和独特的情况可能无法有效应对。
AI系统的构建...</p></div><div class="meta cap"><span class="cap" id="post-meta">发布于&nbsp;<time datetime="2023-07-23T06:42:24.000Z">2023-07-23</time></span><span class="cap breadcrumb">随笔</span></div></article>
</a><a class="post-card post " href="/2023/07/22/use-ai-to-train-ai/">
<article class="md-text"><div class="post-cover"><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://s1.ax1x.com/2023/07/22/pCqt6Qx.jpg"/></div><h2 class="post-title">用AI生成数据训练AI会有问题吗？</h2><div class="excerpt"><p>让我们从一个不那么恰当的类比开始——一个人，通过读自己原创的书稿，能受到新的启发、获得能力的提升吗？不必急着回答，因为AI大模型的学习机制，和人类的学习机制，是截然不同的。但可以肯定，至少有一点人比AI靠谱——人不会因为看自己的作品失忆、变坏、变笨，目前的AI呢，还真不一定……
首先，AI生成的数据良莠不齐，且难以分辨。以目前的大型语言模型(LLM)为例，在生成文本时，通常会在每个步骤中做出...</p></div><div class="meta cap"><span class="cap" id="post-meta">发布于&nbsp;<time datetime="2023-07-22T14:04:37.000Z">2023-07-22</time></span><span class="cap breadcrumb">随笔</span></div></article>
</a></div>
  
  <div class='paginator-wrap dis-select'>
  <span class="extend prev" rel="prev"></span><span class="page-number current">1</span><a class="page-number" href="/tags/LLM/page/2/">2</a><a class="extend next" rel="next" href="/tags/LLM/page/2/"></a>
  </div>






      
<footer class="page-footer reveal fs12"><hr><div class="text"><p>本站由 <a href="/">@anonymity</a> 使用 <a target="_blank" rel="noopener" href="https://github.com/xaoxuu/hexo-theme-stellar">Stellar</a> 主题创建。<br>本博客所有文章除特别声明外，均采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议，转载请注明出处。</p>
</div></footer>

      <div class='float-panel mobile-only blur' style='display:none'>
  <button type='button' class='sidebar-toggle mobile' onclick='sidebar.toggle()'>
    <svg class="icon" style="width: 1em; height: 1em;vertical-align: middle;fill: currentColor;overflow: hidden;" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="15301"><path d="M566.407 808.3c26.9-0.1 49.3-20.8 51.6-47.6-1.9-27.7-23.9-49.7-51.6-51.6h-412.6c-28.2-1.4-52.6 19.5-55.5 47.6 2.3 26.8 24.6 47.5 51.6 47.6h416.5v4z m309.3-249.9c26.9-0.1 49.3-20.8 51.6-47.6-2.2-26.8-24.6-47.5-51.6-47.6h-721.9c-27.7-2.8-52.5 17.4-55.3 45.1-0.1 0.8-0.1 1.7-0.2 2.5 0.9 27.2 23.6 48.5 50.7 47.6H875.707z m-103.1-245.9c26.9-0.1 49.3-20.8 51.6-47.6-0.4-28.3-23.2-51.1-51.5-51.6h-618.9c-29.5-1.1-54.3 21.9-55.5 51.4v0.2c1.4 27.8 25.2 49.2 53 47.8 0.8 0 1.7-0.1 2.5-0.2h618.8z" p-id="15302"></path><path d="M566.407 808.3c26.9-0.1 49.3-20.8 51.6-47.6-1.9-27.7-23.9-49.7-51.6-51.6h-412.6c-28.2-1.4-52.6 19.5-55.5 47.6 1.9 27.7 23.9 49.7 51.6 51.6h416.5z m309.3-249.9c26.9-0.1 49.3-20.8 51.6-47.6-2.2-26.8-24.6-47.5-51.6-47.6h-721.9c-27.7-2.8-52.5 17.4-55.3 45.1-0.1 0.8-0.1 1.7-0.2 2.5 0.9 27.2 23.6 48.5 50.7 47.6H875.707z m-103.1-245.9c26.9-0.1 49.3-20.8 51.6-47.6-0.4-28.3-23.2-51.1-51.5-51.6h-618.9c-29.5-1.1-54.3 21.9-55.5 51.4v0.2c1.4 27.8 25.2 49.2 53 47.8 0.8 0 1.7-0.1 2.5-0.2h618.8z" p-id="15303"></path></svg>
  </button>
</div>

    </div>
  </div>
  <div class='scripts'>
    <script type="text/javascript">
  const stellar = {
    // 懒加载 css https://github.com/filamentgroup/loadCSS
    loadCSS: (href, before, media, attributes) => {
      var doc = window.document;
      var ss = doc.createElement("link");
      var ref;
      if (before) {
        ref = before;
      } else {
        var refs = (doc.body || doc.getElementsByTagName("head")[0]).childNodes;
        ref = refs[refs.length - 1];
      }
      var sheets = doc.styleSheets;
      if (attributes) {
        for (var attributeName in attributes) {
          if (attributes.hasOwnProperty(attributeName)) {
            ss.setAttribute(attributeName, attributes[attributeName]);
          }
        }
      }
      ss.rel = "stylesheet";
      ss.href = href;
      ss.media = "only x";
      function ready(cb) {
        if (doc.body) {
          return cb();
        }
        setTimeout(function () {
          ready(cb);
        });
      }
      ready(function () {
        ref.parentNode.insertBefore(ss, before ? ref : ref.nextSibling);
      });
      var onloadcssdefined = function (cb) {
        var resolvedHref = ss.href;
        var i = sheets.length;
        while (i--) {
          if (sheets[i].href === resolvedHref) {
            return cb();
          }
        }
        setTimeout(function () {
          onloadcssdefined(cb);
        });
      };
      function loadCB() {
        if (ss.addEventListener) {
          ss.removeEventListener("load", loadCB);
        }
        ss.media = media || "all";
      }
      if (ss.addEventListener) {
        ss.addEventListener("load", loadCB);
      }
      ss.onloadcssdefined = onloadcssdefined;
      onloadcssdefined(loadCB);
      return ss;
    },

    // 从 butterfly 和 volantis 获得灵感
    loadScript: (src, opt) => new Promise((resolve, reject) => {
      var script = document.createElement('script');
      if (src.startsWith('/')){
        src = stellar.config.root + src.substring(1);
      }
      script.src = src;
      if (opt) {
        for (let key of Object.keys(opt)) {
          script[key] = opt[key]
        }
      } else {
        // 默认异步，如果需要同步，第二个参数传入 {} 即可
        script.async = true
      }
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    }),

    // https://github.com/jerryc127/hexo-theme-butterfly
    jQuery: (fn) => {
      if (typeof jQuery === 'undefined') {
        stellar.loadScript(stellar.plugins.jQuery).then(fn)
      } else {
        fn()
      }
    }
  };
  stellar.version = '1.19.0';
  stellar.github = 'https://github.com/xaoxuu/hexo-theme-stellar/tree/1.19.0';
  stellar.config = {
    date_suffix: {
      just: '刚刚',
      min: '分钟前',
      hour: '小时前',
      day: '天前',
      month: '个月前',
    },
    root : '/',
  };

  // required plugins (only load if needs)
  stellar.plugins = {
    jQuery: 'https://gcore.jsdelivr.net/npm/jquery@3.6.2/dist/jquery.min.js'
  };

  if ('local_search') {
    stellar.search = {};
    stellar.search.service = 'local_search';
    if (stellar.search.service == 'local_search') {
      let service_obj = Object.assign({}, {"field":"all","path":"/search.json","content":true,"sort":"-date"});
      stellar.search[stellar.search.service] = service_obj;
    }
  }

  // stellar js
  stellar.plugins.stellar = Object.assign({"sites":"/js/plugins/sites.js","friends":"/js/plugins/friends.js","ghinfo":"/js/plugins/ghinfo.js","timeline":"/js/plugins/timeline.js","linkcard":"/js/plugins/linkcard.js","fcircle":"/js/plugins/fcircle.js","weibo":"/js/plugins/weibo.js"});

  stellar.plugins.marked = Object.assign("https://cdn.bootcdn.net/ajax/libs/marked/4.0.18/marked.min.js");
  // optional plugins
  if ('true' == 'true') {
    stellar.plugins.lazyload = Object.assign({"enable":true,"js":"https://gcore.jsdelivr.net/npm/vanilla-lazyload@17.8.3/dist/lazyload.min.js","transition":"blur"});
  }
  if ('true' == 'true') {
    stellar.plugins.swiper = Object.assign({"enable":true,"css":"https://unpkg.com/swiper@8.4.5/swiper-bundle.min.css","js":"https://unpkg.com/swiper@8.4.5/swiper-bundle.min.js"});
  }
  if ('' == 'true') {
    stellar.plugins.scrollreveal = Object.assign({"enable":null,"js":"https://gcore.jsdelivr.net/npm/scrollreveal@4.0.9/dist/scrollreveal.min.js","distance":"8px","duration":500,"interval":100,"scale":1});
  }
  if ('true' == 'true') {
    stellar.plugins.preload = Object.assign({"enable":true,"service":"flying_pages","instant_page":"https://gcore.jsdelivr.net/gh/volantis-x/cdn-volantis@4.1.2/js/instant_page.js","flying_pages":"https://gcore.jsdelivr.net/gh/gijo-varghese/flying-pages@2.1.2/flying-pages.min.js"});
  }
  if ('true' == 'true') {
    stellar.plugins.fancybox = Object.assign({"enable":true,"js":"https://gcore.jsdelivr.net/npm/@fancyapps/ui@4.0/dist/fancybox.umd.js","css":"https://gcore.jsdelivr.net/npm/@fancyapps/ui@4.0/dist/fancybox.css","selector":".swiper-slide img"});
  }
  if ('false' == 'true') {
    stellar.plugins.heti = Object.assign({"enable":false,"css":"https://unpkg.com/heti@0.9.2/umd/heti.min.css","js":"https://unpkg.com/heti@0.9.2/umd/heti-addon.min.js"});
  }
  if ('true' == 'true') {
    stellar.plugins.copycode = Object.assign({"enable":true,"js":"/js/plugins/copycode.js","default_text":"Copy","success_text":"Copied"});
  }
</script>

<!-- required -->

  
<script src="/js/main.js" async></script>



<!-- optional -->



<!-- inject -->


  </div>
</body>
</html>

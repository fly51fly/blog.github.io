[{"title":"LLaMA2不是真正意义上的“开源”","path":"/2023/07/22/llama2-isnt-open-source/","content":"原文：LLaMA2 isn’t “Open Source” - and why it doesn’t matter LLaMA2模型被称为“开源”，但其实并不完全符合传统开源的含义。该模型虽然在很多方面是开放的，但也存在一些限制，比如对商业使用的限制以及不允许用其输出结果来训练其他大型语言模型。虽然有些人对这种模糊的开源定义感到不满，但对于人工智能模型来说，“开源”这个术语需要不断演变。当前，许多AI工程师认为“开源”意味着“可下载的权重”，即使没有全部源代码，也能从这些权重开始工作。然而，真正的开源模型应该提供所有的训练代码、预训练数据集等，但由于高昂的训练成本，许多人更倾向于获得最终的模型权重。在人工智能领域，对“开源”和“开放权重”这两个术语的使用常常相互交叉，而更重要的是让越来越多的工作尽可能地以开放的方式进行。尽管对LLaMA2的许可证感到失望，但Meta公司在GitHub上发布了价值约200万美元的FLOPS计算资源，这对该领域的进展将产生积极的影响。 要点： LLaMA2模型被称为“开源”，但其实并不符合传统意义上的“开源”概念。 尽管LLaMA2模型在很大程度上是开放的，但仍有一些限制，例如，如果使用该模型的商业月活跃用户超过7亿，或者将该模型输出用于训练另一个大型语言模型，都是不允许的。 “开源”一词在人工智能模型领域需要进一步演变。 自由软件和开源运动的历史，自1976年的“业余爱好者公开信”起，就一直存在着商业软件公司和想要规避其限制的黑客之间的紧张关系。 “开源”一词是在1998年由MIT的Christine Peterson提出的，作为“免费软件”一词的替代。 在过去的十年里，由于商业开源公司和云超大规模服务提供商之间的紧张关系，出现了另一种分歧，一些项目采用“服务器端公共许可证”（SSPL）以限制云服务提供商对其产品的使用。 现在随着Dolly、MPT、LLaMA等开源模型的崛起，社区也面临着类似的分歧，对于大多数AI工程师来说，如今的“开源”意味着“可下载权重”。 要使一个模型真正成为开源且可从头开始重新训练，创建者需要共享所有训练代码、预训练数据集、微调偏好、RLHF（Reinforcement Learning from Human Feedback）示例等。然而，由于这些训练过程成本较高，许多开发者和公司很难从头开始训练模型，所以获得最终的预训练权重通常已经足够。 在LLM领域，术语“开源”被用来定义各种不同的开放程度，包括：开放模型、开放权重、受限权重和受污染权重等。 目前，开源和开放权重会被互换使用，但更重要的是越来越多的工作以尽可能开放的方式进行。尽管可能对LLaMA2的许可证感到失望，但Meta公司仍将约2百万美元的浮点运算包含在了GitHub库中，这将对该领域的进展产生积极的影响。","tags":["LLM"],"categories":["文摘"]},{"title":"Meta为何选择开源Llama 2？","path":"/2023/07/22/why-did-meta-open-source-llama/","content":"原文：Why Did Meta Open-Source Llama 2? 讨论了Meta公司推出的商业开源模型Llama 2。该模型是基于之前的“仅限学术使用”的模型LLaMA的进一步发展，对任何能点击下载链接的人都是可用的。文中提出了Meta公司公开Llama 2模型权重的原因，主要包括：招聘、营销、推向市场（免费版或补充功能）、削弱竞争对手壁垒、 goodwill（增进美誉度）、标准游说等不同的战略用途。同时，文中也列出了将机器学习模型开源的四个具体原因。 通过分析Llama 2的许可证，有人推测Meta公司开源该模型的目标：削弱竞争对手的优势地位，尤其是对于那些拥有专有模型的公司，以及那些需要有机地建立自己受众群体的公司。此外，Meta公司还可能通过提供其他配套产品来推向市场，例如LLM技术在Instagram &#x2F; Threads &#x2F; Facebook等平台的应用，专门设计的芯片和数据中心，以及在PyTorch中使用的机器学习框架等。 总体来说，通过开源Llama 2，Meta公司有望在人工智能领域树立先进科技的形象，从而获得开发者、用户和媒体的好评。然而，这也是一个具有挑战性的过程，需要认真对待。 要点： Llama 2 是 Meta 推出的一个商业可用的开源模型，是基于之前的“仅限学术用途”的 LLaMA 模型的升级版。 Meta 为什么会将 Llama 2 的权重商业化？这需要进行深入的分析。 在《开源战略简明分类》中，对开源战略进行了七种不同的分类：招聘、营销、推向市场（补充性）、推向市场（免费层级）、削弱竞争对手的优势、善意和标准游说。 同样，在《为何开源一个模型？》中，针对机器学习模型列出了四个更具体的原因：拥有专有数据但没有足够的资源或专业知识、招募和留住顶级研究人员、销售硬件或云资源、没有分销但有突破性的见解。 通过对 Llama 2 的许可证进行分析，可以推测出 Meta 的目标。其中包括：不允许将 Llama 材料或其任何输出或结果用于改进其他大型语言模型（Llama 2 或其衍生作品除外）；对竞争对手施加限制，如果许可证持有者在版本发布后的前一个月内拥有超过 7 亿活跃用户，需要向 Meta 申请许可，并经 Meta 许可后才能行使本协议下的任何权利；保留品牌和营销权利。 通过框架、发布公告和许可证的分析，可以提出一些关于 Meta 开源 Llama 2 的假设：减弱竞争对手的优势，特别是那些拥有专有模型的公司，如 Google 和 OpenAI（以及 Microsoft）；采用免费层级或补充性推向市场策略，利用较小规模的 Llama 2 模型作为自助式的免费版本，吸引用户使用 Meta 提供的未来服务，比如庞大的模型或高度实时的在线服务；利用开源策略进行营销，打造一个以创新为核心的企业形象，类似于 Google 过去几十年建立的声誉。","tags":["LLM"],"categories":["文摘"]},{"title":"沉迷工具不会让你成为大师","path":"/2023/07/10/Amateurs-obsess-over-tools-pros-over-mastery/","content":"原文：Amateurs obsess over tools, pros over mastery 在我们越来越受科技潮流影响的世界中，很容易陷入对新工具的迷恋。无论是最新的生产力应用程序还是华而不实的小工具，我们不断被承诺提高效率、增加产出和实现成功（无论是创意还是财务方面）。我们沉迷于这些工具，将它们视为一种迷恋，一时迷住我们的注意力。然而，这一切都是徒劳和幻想。 当然，如果你与经验丰富的专业人士或你真正尊重的业内人士聊聊，会发现一个共同点：单凭工具并不能造就大师。伟大不是由最新的软件或最快的硬件决定的，而是由使用它们的个体的心态和技能决定的。正如哲学家塞内加曾经说过的：“剑从不杀人，它只是杀手的工具而已。” 以原声吉他为例，在数字音乐制作和合成器的时代，单独演奏这种乐器可能显得过时。然而，在熟练的音乐家手中，它变成了一个充满迷人旋律和震撼灵魂的容器。它甚至可能激发出一些更大的灵感，如果你直接使用软件可能会错过。这种乐器的简单性迫使艺术家专注于自己演奏的细微差别，提炼指弹技巧，并通过每一次弹奏传达情感。真正的魔力不在于吉他本身，而在于将其演绎到极致的音乐家的精湛技艺。 类似地，数字世界充斥着承诺革新我们工作和创造方式的工具。但如果我们专注于获取每一个新工具，我们就有可能错过发展我们基本、永恒技能的机会——那些超越技术潮流、持续存在的能力。过于关注这些工具几乎总是事与愿违。重要的工具会找到你。这也不是创造出伟大作品的真正堡垒或秘诀。也许只有“快人一步”的临时快感，但这又有何意义呢？ 真正的专家明白锤炼自己技艺的重要性，不论手头有何工具。通过有意识、持续的实践和对基本原理的深入理解获得的专业知识将专业人士与业余爱好者区分开来。 摒弃对新奇事物的诱惑，专注于基础、永恒的原则和对精通的不懈追求，这才是真正的优势。具有讽刺意味的是，人工智能将使这一点更加真实。这也将确保你不会陷入对依赖人工智能创造的虚无主义。 下次你发现自己追逐最新的小工具或潮流应用时，停下来反思一下。问问自己：我真正在磨砺自己的技艺吗？我在这里的投资只是因为别人告诉我吗？我真的在做一些有意义的事吗？我是不是只是在追逐一个闪亮的诱饵的金鱼？在这个更常见的成为最新潮流的普通股票推销员的世界里，我担心很多人缺乏这种元认知。也许对你来说，不要这样做，而是去做更困难的事情，这将成为你的超能力。 要点： 在科技潮流驱动的世界中，我们很容易被新工具的诱惑所吸引。 最新的生产力应用程序和高科技小工具让我们不断听到提高效率、增加产出和实现成功的承诺。 然而，这些工具并不是成就伟大的关键，真正重要的是运用它们的个体的心态和技能。 一个工具从未能使人杀人，它只是杀手手中的一种工具，正如哲学家塞内加所说。 与此类似，数字世界中充斥着承诺革新我们工作和创造方式的工具。 如果我们一味追求每一个新工具，我们就可能错过发展基本、永恒技能的机会，这些技能超越了技术的潮流并延续至今。 真正的专业人士明白，无论拥有何种工具，磨练自己的技艺是至关重要的。 正确的做法是专注于基础、永恒的原则，并不懈追求精湛的技艺。 AI的出现更加凸显了这一点，并确保你不会对依赖AI创造力的虚无主义产生依赖。 当你发现自己追求最新小工具或时髦应用时，停下来反思一下。 问问自己：我真正在磨练我的技艺吗？我之所以投资于此仅仅是因为别人告诉我吗？ 我真正做的是一些有意义的事情吗？我是不是只是一个追逐闪亮诱饵的金鱼？ 在一个更倾向于成为最新潮流的股票推销员的世界中，许多人可能缺乏这种元认知能力。 请尝试摒弃这种追逐新奇的诱惑，而是专注于更困难的事情。","categories":["文摘"]},{"title":"AI权重开\"源\"怎么论","path":"/2023/07/06/AI_weights_are_not_open_source/","content":"原文：AI weights are not open “source” AI权重与源码本质上不同，许多“免费使用”许可证包含使用限制。当AI权重没有使用限制时，我们应该称之为“Open Weights”，当有使用限制时，应称之为“Ethical Weights”。AI许可证非常复杂。与软件许可证不同，AI不像应用当前专有&#x2F;开源软件许可证那样简单。AI具有多个组成部分-源码、权重、数据等-它们的许可方式不同。AI还带来了在计算机软件领域不存在的社会伦理后果，因此需要更多的限制，比如行为使用限制，有时还有分发限制。由于这些复杂性，AI许可证具有多个层次，包括多个组成部分和附加许可考虑因素。根据Heather Meeker的意见，本文创建了一套分类，以规范谈论AI许可证的方式。 要点： AI权重与源代码有本质区别，许多“免费使用”许可证包含使用限制。 当没有使用限制时，应称开放的AI权重为“Open Weights”，当有使用限制时应称为“Ethical Weights”。 AI许可证非常复杂，与软件许可证不同，AI具有多个组成部分（源码、权重、数据等），这些部分具有不同的许可方式。 AI许可证还涉及社会伦理后果，这在计算机软件上并不存在相同规模的问题，因此需要更多的限制，如行为使用限制和分发限制。 AI许可证有许多层次，包括多个组成部分和额外的许可考虑因素。 本文提出一套分类，以便规范对AI许可证的讨论。分类包括专有许可证、合作者许可证、可用许可证、伦理许可证和开放许可证。 “开放权重”已成为“开放源码”AI权重的默认名称。已经提出了Open Weights的定义和许可框架，旨在保留自由软件的零自由和开源的非歧视原则。 对于每个类别，最终需要标准定义和许可框架。 源代码和权重是两个不同的概念，权重不是源码，不能称为“开源”。需要针对权重设计专门的许可证类别。 为避免“开源洗白”，需要更好的定义。将允许自由开放使用的许可证称为“伦理许可证”，避免混淆并为模型使用者提供明确的说明。 需要使用正确的术语，如“Open Weights和“Ethical Weights”，以便在发展各个许可证类别的标准时推动行业的发展。 许多标有“开源”的AI权重实际上并不是开源的，它们根本不是源码。使用正确的术语，如“Ethical Weights”和“Open Weights”，将有助于行业发展各个类别的标准化。","tags":["LLM"],"categories":["文摘"]},{"title":"AIGC时代程序员如何保持领先","path":"/2023/07/05/4_tips_for_programmers_to_stay_ahead_of_generative_AI/","content":"原文：How Coders Can Survive—and Thrive—in a ChatGPT World &gt; 4 tips for programmers to stay ahead of generative AI 这篇文章主要讨论了在大型语言模型(LLM)驱动的生成式人工智能(AI)世界中，程序员如何保持自身的价值和相关性。以下是文章的主要要点： 坚持基本技能和最佳实践：尽管AI编程助手可以帮助完成代码和生成代码，但编程的基本能力仍然是必需的，包括阅读和理解自己和他人的代码，以及理解你编写的代码如何适应更大的系统。此外，解决问题的能力仍然是人类程序员的核心技能。 找到适合你需求的工具：找到合适的AI工具至关重要。每个工具都有自己的交互方式，有不同的方式将每个工具融入你的开发工作流程。例如，GitHub Copilot和其他AI编程助手可以在你编程时提供建议，而ChatGPT和Google的Bard更像是会话型AI程序员，可以用来回答关于API的问题或生成代码片段。 清晰、精确的对话至关重要：使用AI编程助手时，需要详细说明你的需求，并将其视为一个迭代过程。对于会话型AI程序员，你需要知道如何最好地构建你的提示。这就需要提示工程。 批判性思考和理解风险：软件工程师应对大型语言模型的输出持批判性态度，因为它们往往会产生不准确或错误的代码。因此，检查生成的代码至关重要。此外，开发者还应警惕将专有代码输入这些模型。一些公司，如Tabnine，提供了他们的AI编程助手的企业版本，既可以保护隐私，又可以学习组织的编码模式和风格。 安全问题：这些模型可能会生成包含漏洞的代码。软件开发的最佳实践，如代码审查和强大的测试管道，可以帮助防范这种风险。 总的来说，程序员在生成式AI世界中生存下来，他们需要将AI视为一个工具，并将AI融入他们的工作流，同时认识到这些工具的机会和限制，并依靠他们的人类编码能力来发展。","tags":["AIGC"],"categories":["文摘"]},{"title":"科研数据分享最佳实践","path":"/2023/06/29/How-to-make-your-scientific-data-accessible-discoverable-and-useful/","content":"原文：How to make your scientific data accessible, discoverable and useful 研究人员越来越倾向于在发表论文时将数据一并公开，但并非每个期刊都要求作者公开数据集，有些作者因为担心被抢先发表或者时间不足而拒绝公开数据。数据科学家提出了一些发布高质量、可用数据的最佳实践：完善元数据、共享尽可能多的数据、采用标准化格式、附上代码以及考虑数据的可访问性。 要点： 研究人员越来越多地将数据与论文一起提交，以支持开放科研和可重复性。然而，并非每个期刊都要求作者提供数据集，有些作者也因担心被抢先发表或时间不够而拒绝提供数据。 数据的元数据是使数据具有价值的关键，元数据是描述数据的数据，对于使数据具备可发现性、可访问性、可互操作性和可重用性至关重要，可以通过“README”文本文件来提供数据的详细说明。 数据的原始版本和衍生版本都应该共享，原始数据可以让其他研究人员测试假设和处理策略，如果无法存储原始数据，至少应该发布用于生成图表的数据。 建议遵循行业的标准和指南，将数据存储在专门的数据库或存档中，并使用开放、非专有的文件格式。 如果使用了代码进行数据分析，应将代码与数据一起发布，并确保代码易于理解和运行。 考虑到使用者的可访问性，应该咨询相关组织对数据标准和假设进行反馈，并设法确保数据的易用性和可重复性。","tags":["Academic","Data"],"categories":["文摘"]},{"title":"图解：私有知识库LLM聊天机器人","path":"/2023/06/28/LLM-based-Chatbot-to-query-Private-Knowledge-Base/","content":"原文：LLM based Chatbot to query Private Knowledge Base LLM based Chatbot to query Private Knowledge Base 将整个知识库的文本语料分割成多个块——每个块表示一个可查询的上下文片段，知识数据可以来自多个源； 用嵌入(Embedding)模型将每个块转换为一个向量； 将所有向量存储在向量数据库； 分别保存表示每个嵌入向量的文本，同时保存指向该向量的指针。 使用与嵌入知识库本身所使用的相同的嵌入模型，将要提问的问题&#x2F;查询进行嵌入，转换成向量； 使用生成的向量在向量数据库的索引中运行一个查询。选择要从向量数据库中检索多少个向量 - 这将等于您将要检索和最终用于回答查询问题的上下文数量； 向量数据库对所提供的向量执行近似最近邻(ANN)搜索，并返回之前选择的上下文向量的数量。该过程返回在给定的嵌入&#x2F;潜空间中最相似的向量； 将返回的向量嵌入映射到对应的文本块； 将问题与检索到的上下文文本块一起传给LLM(大语言模型)，通过提示指示LLM仅使用提供的上下文来回答给定的问题。这并不意味着不需要进行提示工程 - 需要确保LLM返回的答案符合预期的范围，例如，如果在检索到的上下文中没有可用的数据，则确保不提供虚构的答案。","tags":["LLM","ChatGPT","Chatbot"],"categories":["文摘"]},{"title":"LLM赋能的自主智能体(Agent)","path":"/2023/06/28/LLM-Powered-Autonomous-Agents/","content":"原文：LLM Powered Autonomous Agents 以LLM（大型语言模型）作为核心控制器构建智能体的概念很酷。一些概念验证演示，如AutoGPT、GPT-Engineer和BabAGI，都是令人鼓舞的示例。LLM的潜力不仅限于生成书面副本、故事、论文和程序，它可以被视为强大的通用问题求解器。LLM驱动的自主智能体系统概述：LLM作为智能体的大脑，配合几个关键组件：子目标规划和分解、反思和改进、短期记忆、长期记忆和工具使用。该系统还包括记忆类型、最大内积搜索(MIPS)算法、工具使用能力的案例研究，以及AutoGPT等概念验证示例。 要点： 建立以大型语言模型(LLM)为核心控制器的智能体系统是一个很酷的概念。 LLM的潜力不仅限于生成文本、故事、论文和程序，它还可以被视为一个强大的通用问题求解器。 智能体系统的核心组成部分包括规划、反思、记忆和工具使用。 规划：将复杂任务分解为可管理的子目标，实现对复杂任务的高效处理。 反思和改进：智能体可以对过去的行动进行自我批评和反思，从错误中学习并改进，提高最终结果的质量。 记忆：短期记忆用于模型的上下文学习，长期记忆通过外部向量存储和快速检索提供了无限的信息存储和回忆能力。 工具使用：智能体学习调用外部API获取模型权重中缺失的额外信息，包括当前信息、代码执行能力、专有信息源等。 LLM+P方法利用外部经典规划器进行长程规划，通过PDDL语言描述规划问题，将规划步骤外包给外部工具。 自反思：智能体通过结合任务特定的离散动作和语言空间来进行自反思，从而改进决策和行动，提高推理能力。 CoH通过向模型提供过去输出的历史序列和反馈来改进模型的输出质量。 算法蒸馏利用交叉轮次历史训练神经网络，学习强化学习算法的过程而非任务特定的策略。 记忆分为感觉记忆、短期记忆和长期记忆，长期记忆可以通过外部向量存储和快速检索进行扩展。 外部记忆通常使用最大内积搜索(MIPS)算法进行快速检索，常用的算法包括LSH、ANNOY、HNSW、FAISS和ScaNN。 工具使用可以显著扩展模型的能力，如调用API、使用外部模块等。 MRKL是一个神经符号化架构，将LLM与多个专家模块结合起来，根据任务选择合适的模块。 HuggingGPT是一个使用LLM作为任务规划器的框架，根据模型描述选择合适的模型并提供执行结果的总结。 API-Bank是一个评估工具增强LLM性能的基准，包含常用API工具、完整的工具增强LLM流程和带有API调用的对话数据集。 ChemCrow是一个领域特定的示例，LLM与专家设计的工具结合，用于完成有机合成、药物发现和材料设计等任务。 Generative Agents是一个基于LLM的虚拟角色模拟实验，结合记忆、规划和反思机制，实现了智能体之间的互动行为。 AutoGPT是一个证明概念的示例，展示了将LLM作为主控制器的可能性，但在可靠性方面存在一些问题。","tags":["LLM","Agent","ChatGPT"],"categories":["文摘"]},{"title":"学术界能否与资源雄厚的工业界相竞争？计算机图形学的历史观点","path":"/2023/06/28/Can-academia-compete-with-the-resources-of-industry/","content":"原文：Can academia compete with the resources of industry? - A historical perspective from Computer Graphics 文章探讨了学术界与资源雄厚的工业界相竞争的问题。作者回顾了计算机图形学领域的发展历程，并指出工业界在数据规模、计算集群和工程团队等方面具有优势。然而，学术界并没有试图复制工业界的成就，而是专注于一些被工业界忽视的领域，如物理模拟、光照模拟、外观模型和机器学习等。随着时间的推移，学术界的研究成果逐渐影响了计算机图形学的渲染技术，并在图形硬件方面取得了一定的贡献。文章指出学术界的盲点和困境，同时强调了在学术研究中的重要原则，包括专注于长期目标、学习非主流技术、开放合作和保持乐趣等。总体而言，学术界在计算机图形学领域中扮演着重要的角色，并与工业界共同推动了该领域的发展。 要点： AI研究的规模让人们担心学术界在资源方面是否能与工业界竞争。 回顾计算机图形学领域，作者回忆起25年前作为博士生时的经历，当时工业界在资源方面具有明显优势。 工业界在规模方面具有优势，包括输入训练数据、计算集群和工程团队等方面，学术界无法与之匹敌。 学术界并没有试图复制工业界的成就，而是探索不同的方法，并专注于工业界认为不太重要的领域，如光线和动作的物理模拟。 学术界在许多领域进行了研究，包括光照模拟、基于图像的建模和光照、皮肤和头发的外观模型、衣物和流体等的物理模拟，以及动画的机器学习等创新领域。 随着时间推移，计算机图形学中的渲染技术在很大程度上依赖于学术界的研究，如蒙特卡洛路径追踪、材质外观模型、基于图像的光照和非真实感渲染。 学术界也在图形硬件方面做出了贡献，开创了灵活的硬件、光线追踪硬件和通用计算在GPU上的应用。 计算机图形学中的学术研究使该领域更加数学化，对离散微分几何、蒙特卡洛路径追踪、流体模拟等实际解决方案产生了影响。 作者提到自己参与了Halide的开发，这是一种用于高性能图像处理的编程语言和编译器，获得了工业界的成功采用。 学术界和工业界都对计算机图形学做出了重要贡献，而工业界通常在学术界广泛接受之前引领了具有范式变革意义的创新。 作者强调学术界存在盲点，并指出计算机图形学直到90年代才得到广泛认可。 从历史的角度得出的教训包括致力于不同的研究方向，学习非主流的技能和技术，探索现实世界的问题，质疑假设，专注于长期目标，开源和合作等。 工业界对学术思想进行改进是自然的顺序，学术界应专注于理论、理解和战略优势的发展。 强调小型、灵活的团队、系统思维以及在计算机图形学领域保持乐趣的重要性。","tags":["Research"],"categories":["文摘"]},{"title":"Open LLM Leaderboard排名之谜","path":"/2023/06/27/What_s_going_on_with_the_Open_LLM_Leaderboard/","content":"原文：What’s going on with the Open LLM Leaderboard? 本文讨论了Open LLM Leaderboard上MMLU评估的差异问题。不同的评估实现会给出不同的结果，并且可能改变模型在Leaderboard上的排名。作者强调了评估与实现细节密切相关，开放、标准化和可复现的基准测试对于改进LLM非常重要。介绍了三种不同的MMLU评估实现，即Harness实现、HELM实现和Original实现，并比较了它们的结果。最后，提到将更新EleutherAI Eval Harness，并更新完整的Leaderboard。 要点： Twitter上发布了Falcon，并加入了Open LLM Leaderboard(开放排行榜)，引发了有趣的讨论。 讨论的焦点是排行榜上的四个评估之一：用于衡量”Massive Multitask Language Understanding(MMLU)”的基准。 当前排行榜上排名第一的LLaMA模型的MMLU评估数据明显低于LLaMa论文中的数据，这让社区感到惊讶。 为了弄清楚情况并解决问题，运行了三种不同的MMLU评估实现，并对模型进行了排名。 不同实现方式给出的评估结果差异很大，甚至改变了模型在排行榜上的顺序。 MMLU是一个多项选择题测试，评估方式有多种，其中包括模型生成的概率和生成的文本与预期答案的比较。 在评估过程中，不同实现方式在提示语、模型输出预测等方面存在细微差别。 模型在同一数据集上的得分和排名非常敏感，不同评估方法得出的结果不可比较。 标准化和可复现的评估基准对于比较不同模型和研究成果至关重要。 Open LLM Leaderboard决定采用社区维护的评估库，并更新了MMLU评估的实现以保持一致性。 正在更新完整的排行榜，使用更新后的评估库进行评估。","tags":["LLM","Leaderboard"],"categories":["文摘"]},{"title":"关于大型语言模型评估的思考","path":"/2023/06/27/The_Curious_Case_of_LLM_Evaluations/","content":"原文：The Curious Case of LLM Evaluations 本文讨论了在评估大型语言模型(LLM)时面临的一些复杂问题。评估和基准测试一直是具有挑战性的，而大型多用途模型的出现进一步增加了复杂性。数据泄漏、覆盖范围限制、虚假相关性和分区问题等问题困扰着我们的评估实践。此外，精度与召回的权衡、缺乏真实标准进一步增加了困扰。本文探讨了机器学习评估中的常见问题，并深入研究了LLM所面临的具体挑战。将评估媒介分为直接度量、辅助模型评估和模型驱动评估，并阐明了每种方法的细微差别。在审慎的前提下，探索了如何报告性能指标，并强调了细粒度的重要性。同时，对提示微调进行了审视，并提醒要考虑用户交互的现实性。在深入了解评估领域的同时，明白了对这些复杂性的全面理解对于有意义地评估LLMs至关重要。 要点： 我们的建模、扩展和泛化技术发展得比我们的基准能力快，导致评估不佳和被夸大的能力。 评估和基准已经变得复杂，尤其是对于大型生成模型和长文本生成。 评估中的常见问题包括数据泄漏、覆盖范围不足、虚假相关性、数据集分割和表述问题。 神经网络输出通常与随机种子略有关联，单次推断结果可能会导致错误的结果。 对于不同任务，准确率和召回率的权衡并不相同，需要根据任务的特点进行评估。 在机器学习中存在许多关于数据选择和保留的决策，对于复制和验证研究结果以及论文审查和讨论都很重要。 语言模型评估可以分为六个组成部分：评估数据集、模型输出、样本&#x2F;输出转换、评估媒介、性能报告和参考材料。 评估数据集的构建和使用会引入一系列问题，如模糊性、数据泄漏、覆盖范围和偏见等。 模型输出的评估受到提示和回答方式的影响，需要注意输出的可靠性和一致性。 对模型输出进行转换的方法包括循环变换、链式变换、原子输出和约束输出等。 在评估中使用的基准真实性需要谨慎处理，特别是在考虑到现实场景的情况下。 评估媒介可以分为直接评估指标、间接或分解式模型评估和模型驱动评估。 在报告性能指标时，需要考虑数据集划分和细微变化的影响，并保持适度的怀疑态度。 需要对评估结果的可靠性和统计显著性进行正确解读，避免基于细微差异和单次推断结果宣称显著改进。 对于直接面向用户的端到端模型，需要考虑最佳提示是否适用于所有用户，并理解评估中存在的复杂性。 综合理解这些复杂性对于有意义地评估语言模型至关重要。","tags":["LLM","ChatGPT"],"categories":["文摘"]},{"title":"脚本(Script)与程序(Program)","path":"/2023/06/26/script-vs-program/","content":"原文：Failing to draw lines between ‘script’ and ‘program’ 近期有关于“脚本”与“程序”之间界限的讨论，但人们对于这两者之间的区别并没有明确的界定。有人认为编译语言中的东西总是“程序”，大型或复杂的东西也总是“程序”，即使是解释型语言中的单文件。然而，脚本可能更多地依赖于外部Unix程序而非内部组件。对于扩展其他程序的代码，也存在对于它们是“脚本”还是“程序”的争议。总的来说，计算机术语的界定是一个有趣但也复杂的问题。 要点： 在Fediverse上，有人进行了有关“脚本”与“程序”之间界限的调查。 有人认为，编译语言中的东西总是“程序”，而解释语言中的一个单文件的大型或复杂的东西也总是“程序”。 “脚本”可能更多地依赖于外部的Unix程序，而不是内部的东西。 对于个人而言，即使是小型的Python代码，也会被称为“程序”，而不是“脚本”。 对于某些功能强大的Unix实用程序，人们对其是否为“程序”还是“脚本”存在争议。 有些事物被认为是“脚本”，而不是“程序”，即使它们包含了一些相对复杂的逻辑。 有关扩展其他程序的代码的编写也是一个辩论的重要领域。 总的来说，计算机术语是有趣的，有一种特定的乐趣。","tags":["programming"],"categories":["文摘"]},{"title":"AI工程师入门指南","path":"/2023/06/26/How-to-Break-into-AI-Engineering/","content":"原文：Ask HN: How to Break into AI Engineering 文章提到了学习AI工程所需的技能和知识的一些资源，包括数学基础、统计学、Python编程、IBM数据科学专业证书、机器学习和深度学习专业课程等。还讨论了数学在软件工程师中的重要性以及AI工程的发展趋势。 要点： 要成为AI工程师，需要有扎实的数学基础，尤其是微积分和线性代数。 需要掌握统计学的语言和基本概念。 学习Python编程语言，掌握PyTorch。 推荐学习资源包括IBM Data Science Professional Certificate、Oliver Theobald的《Machine Learning for Absolute Beginners》、Andrew Ng的Coursera课程（包括《Machine Learning Specialization》和《Deep Learning Specialization》）以及fast.ai课程。 在选择AI领域的方向时，可以考虑自然语言处理（NLProc）、视觉处理（Vision）、强化学习（RL）等。 如果想在大型科技公司找工作，需要准备Leetcode面试、学习系统设计和机器学习系统的设计，还可以参考Chip Huyen的相关书籍。 数学在软件工程师中可能变得更加重要，因为AI在软件开发生命周期中的应用越来越广泛。 AI工程师的角色可以分为专注于模型改进、优化模型性能以及将模型应用于大型应用程序的不同方面。 学习数据清洗、数据标注和训练算法的基本过程非常重要，这些内容常常被忽视和低估。 AI工程师可以选择从数据工程入门，然后再专注于AI领域的特定方向。 AI工程师不仅需要技术知识，还需要与科学、数学等领域的知识相结合，可以结合自己的专业背景和兴趣选择方向。 AI工程师的角色可以是数据工程师的一种特殊化，不一定需要成为数学专家，但需要扎实的工程和数据处理能力。 AI工程师可以选择从事机器学习工程、数据工程和运维方面的工作，也可以选择研究工作，但后者通常需要更高的学历和数学基础。 了解数据工程的发展历程可以对AI工程师的角色有所启示，从中可以看到AI工程师可能在软件工程和AI领域之间进行工作。 AI工程师需要不断学习和尝试，掌握最新的技术和工具，并将其应用于实际项目中。 可以借助ChatGPT等工具来获取学习和编码的帮助，但仍需要自己进行实践和验证。 AI工程师的发展可能因不同的公司和行业而异，需要根据实际情况进行选择和发展。","tags":["AI","Engineering","Learning"],"categories":["文摘"]},{"title":"聪明人解决难题可能更慢","path":"/2023/06/26/Intelligent-people-take-longer-to-solve-hard-problems/","content":"原文：Intelligent people take longer to solve hard problems 高智力者解决难题更慢？新研究揭示速度并非决定因素。智力与大脑连接和同步有关。速度和准确性之间存在权衡。 心理学家仍在努力定义智力，对智力测试的有效性存在质疑。高智力得分通常与更快的信息处理速度相关，但德国研究显示这可能不完全正确。研究表明，高智力得分者在解决复杂问题时需要更长时间，因为他们更不容易草率下结论。大脑连接和同步差异与问题解决能力相关。结果挑战了高智力与大脑更快有关的假设，速度和准确性之间存在权衡，慢而费力、更长时间整合信息的认知方式可能更适用于解决更困难的问题。 要点： 心理学家仍在努力定义智力，对于测试智力的有效性也存在质疑。 高智力得分与更快的信息处理或“思维速度”有关，但一项德国研究表明，这可能不是完全正确的。 研究发现，高智力得分的人在解决复杂问题时需要更长的时间，因为他们更不容易草率下结论。 研究还将解决问题的能力与大脑连接性和不同脑区之间的同步联系起来。 大脑扫描研究表明，智力涉及前额顶叶和顶叶之间的网络，因此这些脑区之间的更高同步可能反映了一种调节顶叶处理的前额注意机制。 研究结果挑战了高智力是大脑更快的结果的假设，表明速度并不一定更好，在某些情况下，速度和准确性之间存在权衡，从而导致更好的决策。 对于简单任务，快速的“自动”思维足够做出决策，而在解决更困难的问题时，一种更缓慢、更费力的认知方式可能更好，它支持对相关信息的长时间整合。","tags":["IQ","Intelligence"],"categories":["文摘"]},{"title":"用LLM生成SQL的注意事项","path":"/2023/06/26/Generating_SQL_with_LLMs_for_fun_and_profit/","content":"原文：Generating SQL with LLMs for fun and profit 本文介绍了SQL和查询的概念，指出了使用语言模型生成SQL查询可能存在的安全风险，如恶意查询和数据泄露。文章建议在设计时限制查询类型，并不完全依赖语言模型自动生成代码，以保证系统的可靠性和安全性。 要点： SQL代表结构化查询语言，是一种编程语言。 SQL查询可以执行恶意操作，例如删除或修改表。 使用sqlite甚至可以运行占用CPU的无限循环。 为了防止SQL注入，可以将数据库设置为只读或创建具有最低权限的受限角色。 仍然存在拒绝服务攻击和数据泄露的风险。 在使用语言模型设计查询时，不要让其实时转换自然语言为可执行代码。 LLM可以帮助设计查询，但不能完全信任它们。 在生产系统中，应该在设计阶段确定哪些类型的查询对用户可见，避免不必要的查询。 LLM适合用于查询设计，但不能实时转换自然语言为可执行代码。 不要完全依赖LLM，它们更适合于制作教程和指南，而不是可信赖的生产系统。","tags":["LLM","SQL","programming"],"categories":["文摘"]},{"title":"语义压缩导向编程","path":"/2023/06/25/semantic-compression/","content":"原文：Semantic Compression 这篇文章介绍了一种名为压缩导向编程的有效编码方法，通过重构代码、提取重复代码片段和使用函数来简化代码。这种方法强调简洁、可读性和可扩展性，相比过于追求对象导向编程的复杂方法更为实用。作者通过示例展示了如何通过重构代码来减少冗余和提高代码的可读性、可维护性和可扩展性。他强调了在实际编码中，将重复的代码片段提取出来形成可复用的函数或结构是一种更好的方式，而不是过度强调对象导向编程的方法。 有些程序员过于追求对象导向编程，使用复杂的方法和工具，但实际上简单的代码和函数可以更好地满足需求。通过压缩导向编程，我们可以通过逐步优化和重构代码来达到更高效的编程方式，同时减少开发时间和错误。 在文中，作者以一段C++代码为例，展示了如何通过重构代码、提取重复代码片段并使用结构和函数来简化代码。通过这种方式，代码变得更加简洁、可读性更强，同时也更易于扩展和维护。 以下为本文要点： 对于解决实际问题，首先需要基于问题中的复数名词创建相应的类，如员工类和经理类。 为了将经理类与员工类和人类区分开，需要实现类的继承关系，经理类继承自员工类，员工类继承自人类。 需要添加一个承包商类，承包商类继承自人类，因为承包商不是员工。 为了解决经理类既可以是承包商又可以是全职经理的问题，可以使用类的模板化（templatize）。 程序员应该采用压缩式编程思维，先将代码实现具体功能，再根据重复出现的模式提取出可重用的部分。 将重复代码提取为结构体或函数，以减少代码冗余和提高代码的可读性、可维护性和可扩展性。 编程应以过程为导向，对象是为了实现过程的重用而产生的构造物，而不是过程本身。 通过压缩式编程，代码变得更加简洁和易于理解，可以简化代码的设计和开发过程。 总结：本文介绍了一种名为压缩导向编程的有效编码方法，通过重构代码、提取重复代码片段和使用函数来简化代码。这种方法强调简洁、可读性和可扩展性，相比过于追求对象导向编程的复杂方法更为实用。","tags":["programming","OOP"],"categories":["文摘"]},{"title":"ChatGPT类服务汇总","path":"/2023/06/20/chatgpt/","content":"ChatGPT是由OpenAI开发的大型语言模型，可以理解和生成人类语言，具备生成连贯和上下文相关的回复的能力。 这类服务的主要目的是通过自然语言处理和对话系统技术，为用户提供智能对话和信息交流的能力。以下是ChatGPT类服务可能提供的功能和用途： 聊天机器人：ChatGPT类服务可以用作聊天机器人，与用户进行实时对话。用户可以提问问题、请求帮助、寻求建议，而ChatGPT将根据其训练的知识和上下文生成回复。 客户支持：许多公司和组织使用ChatGPT类服务来提供在线客户支持。用户可以通过对话框与机器人代表进行交流，寻求帮助、解决问题或获得产品或服务的相关信息。 智能助手：ChatGPT类服务可以用作个人助手应用程序的一部分，帮助用户管理日常任务、提供实用信息、制定行程或提供娱乐建议等。它可以根据用户的指令和上下文提供个性化的回复和服务。 教育辅助：ChatGPT类服务可以在教育领域用作学习辅助工具。学生可以向ChatGPT提问问题、请求解释或寻求学习建议。它可以提供参考资料、解答问题或引导学生进行学术研究。 娱乐和游戏：ChatGPT类服务可以用于创建有趣的娱乐和游戏体验。例如，它可以扮演虚拟角色，与用户进行角色扮演游戏，或参与有趣的智力游戏和谜题。 需要注意的是，ChatGPT类服务的功能和用途可能因具体应用程序或平台而异。不同的开发人员和组织可以根据其需求和目标，结合ChatGPT模型的能力来设计和定制各种对话系统应用。 ChatGPT类服务汇总：无需注册 Bard (web-browsing) Vitalentum OraChat Vicuna GPTGO (web-browsing) AnonChatGPT Perplexity AI (web-browsing) NoowAI Character AI BAI Chat iAsk AI (web-browsing) Phind AI (web-browsing) GPT4All (open-source) DeepAI Chat Teach Anything HuggingChat (web-browsing) Forefront AI 需要注册 Poe AI Easy-Peasy AI WriteSonic Sincode AI AI.LS LetsView Chat (only 10 messages allowed) CapeChat Open-Assistant (open-source) GlobalGPT Bing Chat JimmyGPT Codeium (mainly for coding) YouChat Frank AI OpenAI Playground 博客文章写作助手 Copy AI TextCortex AI Marmof HyperWrite WriterX 文档(PDF等)聊天机器人 AnySummary (3 per day) Sharly AI ChatDOC Humata AI Ask Your PDF ChatPDF FileGPT ResearchAide Pensieve AI PDFGPT.IO Docalysis 个人助理聊天机器人 Pi, your personal AI Kuki AI Replika YourHana AI","tags":["LLM","ChatGPT"],"categories":["资源"]}]
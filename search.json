[{"title":"图解：私有知识库LLM聊天机器人","path":"/2023/06/28/LLM-based-Chatbot-to-query-Private-Knowledge-Base/","content":"原文：LLM based Chatbot to query Private Knowledge Base pCdeUHI.png 将整个知识库的文本语料分割成多个块——每个块表示一个可查询的上下文片段，知识数据可以来自多个源； 用嵌入(Embedding)模型将每个块转换为一个向量； 将所有向量存储在向量数据库； 分别保存表示每个嵌入向量的文本，同时保存指向该向量的指针。 使用与嵌入知识库本身所使用的相同的嵌入模型，将要提问的问题&#x2F;查询进行嵌入，转换成向量； 使用生成的向量在向量数据库的索引中运行一个查询。选择要从向量数据库中检索多少个向量 - 这将等于您将要检索和最终用于回答查询问题的上下文数量； 向量数据库对所提供的向量执行近似最近邻(ANN)搜索，并返回之前选择的上下文向量的数量。该过程返回在给定的嵌入&#x2F;潜空间中最相似的向量； 将返回的向量嵌入映射到对应的文本块； 将问题与检索到的上下文文本块一起传给LLM(大语言模型)，通过提示指示LLM仅使用提供的上下文来回答给定的问题。这并不意味着不需要进行提示工程 - 需要确保LLM返回的答案符合预期的范围，例如，如果在检索到的上下文中没有可用的数据，则确保不提供虚构的答案。","tags":["LLM","ChatGPT","Chatbot"],"categories":["文摘"]},{"title":"LLM赋能的自主智能体(Agent)","path":"/2023/06/28/LLM-Powered-Autonomous-Agents/","content":"原文：LLM Powered Autonomous Agents 以LLM（大型语言模型）作为核心控制器构建智能体的概念很酷。一些概念验证演示，如AutoGPT、GPT-Engineer和BabAGI，都是令人鼓舞的示例。LLM的潜力不仅限于生成书面副本、故事、论文和程序，它可以被视为强大的通用问题求解器。LLM驱动的自主智能体系统概述：LLM作为智能体的大脑，配合几个关键组件：子目标规划和分解、反思和改进、短期记忆、长期记忆和工具使用。该系统还包括记忆类型、最大内积搜索(MIPS)算法、工具使用能力的案例研究，以及AutoGPT等概念验证示例。 要点： 建立以大型语言模型(LLM)为核心控制器的智能体系统是一个很酷的概念。 LLM的潜力不仅限于生成文本、故事、论文和程序，它还可以被视为一个强大的通用问题求解器。 智能体系统的核心组成部分包括规划、反思、记忆和工具使用。 规划：将复杂任务分解为可管理的子目标，实现对复杂任务的高效处理。 反思和改进：智能体可以对过去的行动进行自我批评和反思，从错误中学习并改进，提高最终结果的质量。 记忆：短期记忆用于模型的上下文学习，长期记忆通过外部向量存储和快速检索提供了无限的信息存储和回忆能力。 工具使用：智能体学习调用外部API获取模型权重中缺失的额外信息，包括当前信息、代码执行能力、专有信息源等。 LLM+P方法利用外部经典规划器进行长程规划，通过PDDL语言描述规划问题，将规划步骤外包给外部工具。 自反思：智能体通过结合任务特定的离散动作和语言空间来进行自反思，从而改进决策和行动，提高推理能力。 CoH通过向模型提供过去输出的历史序列和反馈来改进模型的输出质量。 算法蒸馏利用交叉轮次历史训练神经网络，学习强化学习算法的过程而非任务特定的策略。 记忆分为感觉记忆、短期记忆和长期记忆，长期记忆可以通过外部向量存储和快速检索进行扩展。 外部记忆通常使用最大内积搜索(MIPS)算法进行快速检索，常用的算法包括LSH、ANNOY、HNSW、FAISS和ScaNN。 工具使用可以显著扩展模型的能力，如调用API、使用外部模块等。 MRKL是一个神经符号化架构，将LLM与多个专家模块结合起来，根据任务选择合适的模块。 HuggingGPT是一个使用LLM作为任务规划器的框架，根据模型描述选择合适的模型并提供执行结果的总结。 API-Bank是一个评估工具增强LLM性能的基准，包含常用API工具、完整的工具增强LLM流程和带有API调用的对话数据集。 ChemCrow是一个领域特定的示例，LLM与专家设计的工具结合，用于完成有机合成、药物发现和材料设计等任务。 Generative Agents是一个基于LLM的虚拟角色模拟实验，结合记忆、规划和反思机制，实现了智能体之间的互动行为。 AutoGPT是一个证明概念的示例，展示了将LLM作为主控制器的可能性，但在可靠性方面存在一些问题。","tags":["LLM","Agent","ChatGPT"],"categories":["文摘"]},{"title":"学术界能否与资源雄厚的工业界相竞争？计算机图形学的历史观点","path":"/2023/06/28/Can-academia-compete-with-the-resources-of-industry/","content":"原文：Can academia compete with the resources of industry? - A historical perspective from Computer Graphics 文章探讨了学术界与资源雄厚的工业界相竞争的问题。作者回顾了计算机图形学领域的发展历程，并指出工业界在数据规模、计算集群和工程团队等方面具有优势。然而，学术界并没有试图复制工业界的成就，而是专注于一些被工业界忽视的领域，如物理模拟、光照模拟、外观模型和机器学习等。随着时间的推移，学术界的研究成果逐渐影响了计算机图形学的渲染技术，并在图形硬件方面取得了一定的贡献。文章指出学术界的盲点和困境，同时强调了在学术研究中的重要原则，包括专注于长期目标、学习非主流技术、开放合作和保持乐趣等。总体而言，学术界在计算机图形学领域中扮演着重要的角色，并与工业界共同推动了该领域的发展。 要点： AI研究的规模让人们担心学术界在资源方面是否能与工业界竞争。 回顾计算机图形学领域，作者回忆起25年前作为博士生时的经历，当时工业界在资源方面具有明显优势。 工业界在规模方面具有优势，包括输入训练数据、计算集群和工程团队等方面，学术界无法与之匹敌。 学术界并没有试图复制工业界的成就，而是探索不同的方法，并专注于工业界认为不太重要的领域，如光线和动作的物理模拟。 学术界在许多领域进行了研究，包括光照模拟、基于图像的建模和光照、皮肤和头发的外观模型、衣物和流体等的物理模拟，以及动画的机器学习等创新领域。 随着时间推移，计算机图形学中的渲染技术在很大程度上依赖于学术界的研究，如蒙特卡洛路径追踪、材质外观模型、基于图像的光照和非真实感渲染。 学术界也在图形硬件方面做出了贡献，开创了灵活的硬件、光线追踪硬件和通用计算在GPU上的应用。 计算机图形学中的学术研究使该领域更加数学化，对离散微分几何、蒙特卡洛路径追踪、流体模拟等实际解决方案产生了影响。 作者提到自己参与了Halide的开发，这是一种用于高性能图像处理的编程语言和编译器，获得了工业界的成功采用。 学术界和工业界都对计算机图形学做出了重要贡献，而工业界通常在学术界广泛接受之前引领了具有范式变革意义的创新。 作者强调学术界存在盲点，并指出计算机图形学直到90年代才得到广泛认可。 从历史的角度得出的教训包括致力于不同的研究方向，学习非主流的技能和技术，探索现实世界的问题，质疑假设，专注于长期目标，开源和合作等。 工业界对学术思想进行改进是自然的顺序，学术界应专注于理论、理解和战略优势的发展。 强调小型、灵活的团队、系统思维以及在计算机图形学领域保持乐趣的重要性。","tags":["Research"],"categories":["文摘"]},{"title":"Open LLM Leaderboard排名之谜","path":"/2023/06/27/What_s_going_on_with_the_Open_LLM_Leaderboard/","content":"原文：What’s going on with the Open LLM Leaderboard? 本文讨论了Open LLM Leaderboard上MMLU评估的差异问题。不同的评估实现会给出不同的结果，并且可能改变模型在Leaderboard上的排名。作者强调了评估与实现细节密切相关，开放、标准化和可复现的基准测试对于改进LLM非常重要。介绍了三种不同的MMLU评估实现，即Harness实现、HELM实现和Original实现，并比较了它们的结果。最后，提到将更新EleutherAI Eval Harness，并更新完整的Leaderboard。 要点： Twitter上发布了Falcon，并加入了Open LLM Leaderboard(开放排行榜)，引发了有趣的讨论。 讨论的焦点是排行榜上的四个评估之一：用于衡量”Massive Multitask Language Understanding(MMLU)”的基准。 当前排行榜上排名第一的LLaMA模型的MMLU评估数据明显低于LLaMa论文中的数据，这让社区感到惊讶。 为了弄清楚情况并解决问题，运行了三种不同的MMLU评估实现，并对模型进行了排名。 不同实现方式给出的评估结果差异很大，甚至改变了模型在排行榜上的顺序。 MMLU是一个多项选择题测试，评估方式有多种，其中包括模型生成的概率和生成的文本与预期答案的比较。 在评估过程中，不同实现方式在提示语、模型输出预测等方面存在细微差别。 模型在同一数据集上的得分和排名非常敏感，不同评估方法得出的结果不可比较。 标准化和可复现的评估基准对于比较不同模型和研究成果至关重要。 Open LLM Leaderboard决定采用社区维护的评估库，并更新了MMLU评估的实现以保持一致性。 正在更新完整的排行榜，使用更新后的评估库进行评估。","tags":["LLM","Leaderboard"],"categories":["文摘"]},{"title":"关于大型语言模型评估的思考","path":"/2023/06/27/The_Curious_Case_of_LLM_Evaluations/","content":"原文：The Curious Case of LLM Evaluations 本文讨论了在评估大型语言模型(LLM)时面临的一些复杂问题。评估和基准测试一直是具有挑战性的，而大型多用途模型的出现进一步增加了复杂性。数据泄漏、覆盖范围限制、虚假相关性和分区问题等问题困扰着我们的评估实践。此外，精度与召回的权衡、缺乏真实标准进一步增加了困扰。本文探讨了机器学习评估中的常见问题，并深入研究了LLM所面临的具体挑战。将评估媒介分为直接度量、辅助模型评估和模型驱动评估，并阐明了每种方法的细微差别。在审慎的前提下，探索了如何报告性能指标，并强调了细粒度的重要性。同时，对提示微调进行了审视，并提醒要考虑用户交互的现实性。在深入了解评估领域的同时，明白了对这些复杂性的全面理解对于有意义地评估LLMs至关重要。 要点： 我们的建模、扩展和泛化技术发展得比我们的基准能力快，导致评估不佳和被夸大的能力。 评估和基准已经变得复杂，尤其是对于大型生成模型和长文本生成。 评估中的常见问题包括数据泄漏、覆盖范围不足、虚假相关性、数据集分割和表述问题。 神经网络输出通常与随机种子略有关联，单次推断结果可能会导致错误的结果。 对于不同任务，准确率和召回率的权衡并不相同，需要根据任务的特点进行评估。 在机器学习中存在许多关于数据选择和保留的决策，对于复制和验证研究结果以及论文审查和讨论都很重要。 语言模型评估可以分为六个组成部分：评估数据集、模型输出、样本&#x2F;输出转换、评估媒介、性能报告和参考材料。 评估数据集的构建和使用会引入一系列问题，如模糊性、数据泄漏、覆盖范围和偏见等。 模型输出的评估受到提示和回答方式的影响，需要注意输出的可靠性和一致性。 对模型输出进行转换的方法包括循环变换、链式变换、原子输出和约束输出等。 在评估中使用的基准真实性需要谨慎处理，特别是在考虑到现实场景的情况下。 评估媒介可以分为直接评估指标、间接或分解式模型评估和模型驱动评估。 在报告性能指标时，需要考虑数据集划分和细微变化的影响，并保持适度的怀疑态度。 需要对评估结果的可靠性和统计显著性进行正确解读，避免基于细微差异和单次推断结果宣称显著改进。 对于直接面向用户的端到端模型，需要考虑最佳提示是否适用于所有用户，并理解评估中存在的复杂性。 综合理解这些复杂性对于有意义地评估语言模型至关重要。","tags":["LLM","ChatGPT"],"categories":["文摘"]},{"title":"脚本(Script)与程序(Program)","path":"/2023/06/26/script-vs-program/","content":"原文：Failing to draw lines between ‘script’ and ‘program’ 近期有关于“脚本”与“程序”之间界限的讨论，但人们对于这两者之间的区别并没有明确的界定。有人认为编译语言中的东西总是“程序”，大型或复杂的东西也总是“程序”，即使是解释型语言中的单文件。然而，脚本可能更多地依赖于外部Unix程序而非内部组件。对于扩展其他程序的代码，也存在对于它们是“脚本”还是“程序”的争议。总的来说，计算机术语的界定是一个有趣但也复杂的问题。 要点： 在Fediverse上，有人进行了有关“脚本”与“程序”之间界限的调查。 有人认为，编译语言中的东西总是“程序”，而解释语言中的一个单文件的大型或复杂的东西也总是“程序”。 “脚本”可能更多地依赖于外部的Unix程序，而不是内部的东西。 对于个人而言，即使是小型的Python代码，也会被称为“程序”，而不是“脚本”。 对于某些功能强大的Unix实用程序，人们对其是否为“程序”还是“脚本”存在争议。 有些事物被认为是“脚本”，而不是“程序”，即使它们包含了一些相对复杂的逻辑。 有关扩展其他程序的代码的编写也是一个辩论的重要领域。 总的来说，计算机术语是有趣的，有一种特定的乐趣。","tags":["programming"],"categories":["文摘"]},{"title":"AI工程师入门指南","path":"/2023/06/26/How-to-Break-into-AI-Engineering/","content":"原文：Ask HN: How to Break into AI Engineering 文章提到了学习AI工程所需的技能和知识的一些资源，包括数学基础、统计学、Python编程、IBM数据科学专业证书、机器学习和深度学习专业课程等。还讨论了数学在软件工程师中的重要性以及AI工程的发展趋势。 要点： 要成为AI工程师，需要有扎实的数学基础，尤其是微积分和线性代数。 需要掌握统计学的语言和基本概念。 学习Python编程语言，掌握PyTorch。 推荐学习资源包括IBM Data Science Professional Certificate、Oliver Theobald的《Machine Learning for Absolute Beginners》、Andrew Ng的Coursera课程（包括《Machine Learning Specialization》和《Deep Learning Specialization》）以及fast.ai课程。 在选择AI领域的方向时，可以考虑自然语言处理（NLProc）、视觉处理（Vision）、强化学习（RL）等。 如果想在大型科技公司找工作，需要准备Leetcode面试、学习系统设计和机器学习系统的设计，还可以参考Chip Huyen的相关书籍。 数学在软件工程师中可能变得更加重要，因为AI在软件开发生命周期中的应用越来越广泛。 AI工程师的角色可以分为专注于模型改进、优化模型性能以及将模型应用于大型应用程序的不同方面。 学习数据清洗、数据标注和训练算法的基本过程非常重要，这些内容常常被忽视和低估。 AI工程师可以选择从数据工程入门，然后再专注于AI领域的特定方向。 AI工程师不仅需要技术知识，还需要与科学、数学等领域的知识相结合，可以结合自己的专业背景和兴趣选择方向。 AI工程师的角色可以是数据工程师的一种特殊化，不一定需要成为数学专家，但需要扎实的工程和数据处理能力。 AI工程师可以选择从事机器学习工程、数据工程和运维方面的工作，也可以选择研究工作，但后者通常需要更高的学历和数学基础。 了解数据工程的发展历程可以对AI工程师的角色有所启示，从中可以看到AI工程师可能在软件工程和AI领域之间进行工作。 AI工程师需要不断学习和尝试，掌握最新的技术和工具，并将其应用于实际项目中。 可以借助ChatGPT等工具来获取学习和编码的帮助，但仍需要自己进行实践和验证。 AI工程师的发展可能因不同的公司和行业而异，需要根据实际情况进行选择和发展。","tags":["AI","Engineering","Learning"],"categories":["文摘"]},{"title":"聪明人解决难题可能更慢","path":"/2023/06/26/Intelligent-people-take-longer-to-solve-hard-problems/","content":"原文：Intelligent people take longer to solve hard problems 高智力者解决难题更慢？新研究揭示速度并非决定因素。智力与大脑连接和同步有关。速度和准确性之间存在权衡。 心理学家仍在努力定义智力，对智力测试的有效性存在质疑。高智力得分通常与更快的信息处理速度相关，但德国研究显示这可能不完全正确。研究表明，高智力得分者在解决复杂问题时需要更长时间，因为他们更不容易草率下结论。大脑连接和同步差异与问题解决能力相关。结果挑战了高智力与大脑更快有关的假设，速度和准确性之间存在权衡，慢而费力、更长时间整合信息的认知方式可能更适用于解决更困难的问题。 要点： 心理学家仍在努力定义智力，对于测试智力的有效性也存在质疑。 高智力得分与更快的信息处理或“思维速度”有关，但一项德国研究表明，这可能不是完全正确的。 研究发现，高智力得分的人在解决复杂问题时需要更长的时间，因为他们更不容易草率下结论。 研究还将解决问题的能力与大脑连接性和不同脑区之间的同步联系起来。 大脑扫描研究表明，智力涉及前额顶叶和顶叶之间的网络，因此这些脑区之间的更高同步可能反映了一种调节顶叶处理的前额注意机制。 研究结果挑战了高智力是大脑更快的结果的假设，表明速度并不一定更好，在某些情况下，速度和准确性之间存在权衡，从而导致更好的决策。 对于简单任务，快速的“自动”思维足够做出决策，而在解决更困难的问题时，一种更缓慢、更费力的认知方式可能更好，它支持对相关信息的长时间整合。","tags":["IQ","Intelligence"],"categories":["文摘"]},{"title":"用LLM生成SQL的注意事项","path":"/2023/06/26/Generating_SQL_with_LLMs_for_fun_and_profit/","content":"原文：Generating SQL with LLMs for fun and profit 本文介绍了SQL和查询的概念，指出了使用语言模型生成SQL查询可能存在的安全风险，如恶意查询和数据泄露。文章建议在设计时限制查询类型，并不完全依赖语言模型自动生成代码，以保证系统的可靠性和安全性。 要点： SQL代表结构化查询语言，是一种编程语言。 SQL查询可以执行恶意操作，例如删除或修改表。 使用sqlite甚至可以运行占用CPU的无限循环。 为了防止SQL注入，可以将数据库设置为只读或创建具有最低权限的受限角色。 仍然存在拒绝服务攻击和数据泄露的风险。 在使用语言模型设计查询时，不要让其实时转换自然语言为可执行代码。 LLM可以帮助设计查询，但不能完全信任它们。 在生产系统中，应该在设计阶段确定哪些类型的查询对用户可见，避免不必要的查询。 LLM适合用于查询设计，但不能实时转换自然语言为可执行代码。 不要完全依赖LLM，它们更适合于制作教程和指南，而不是可信赖的生产系统。","tags":["LLM","SQL","programming"],"categories":["文摘"]},{"title":"语义压缩导向编程","path":"/2023/06/25/semantic-compression/","content":"原文：Semantic Compression 这篇文章介绍了一种名为压缩导向编程的有效编码方法，通过重构代码、提取重复代码片段和使用函数来简化代码。这种方法强调简洁、可读性和可扩展性，相比过于追求对象导向编程的复杂方法更为实用。作者通过示例展示了如何通过重构代码来减少冗余和提高代码的可读性、可维护性和可扩展性。他强调了在实际编码中，将重复的代码片段提取出来形成可复用的函数或结构是一种更好的方式，而不是过度强调对象导向编程的方法。 有些程序员过于追求对象导向编程，使用复杂的方法和工具，但实际上简单的代码和函数可以更好地满足需求。通过压缩导向编程，我们可以通过逐步优化和重构代码来达到更高效的编程方式，同时减少开发时间和错误。 在文中，作者以一段C++代码为例，展示了如何通过重构代码、提取重复代码片段并使用结构和函数来简化代码。通过这种方式，代码变得更加简洁、可读性更强，同时也更易于扩展和维护。 以下为本文要点： 对于解决实际问题，首先需要基于问题中的复数名词创建相应的类，如员工类和经理类。 为了将经理类与员工类和人类区分开，需要实现类的继承关系，经理类继承自员工类，员工类继承自人类。 需要添加一个承包商类，承包商类继承自人类，因为承包商不是员工。 为了解决经理类既可以是承包商又可以是全职经理的问题，可以使用类的模板化（templatize）。 程序员应该采用压缩式编程思维，先将代码实现具体功能，再根据重复出现的模式提取出可重用的部分。 将重复代码提取为结构体或函数，以减少代码冗余和提高代码的可读性、可维护性和可扩展性。 编程应以过程为导向，对象是为了实现过程的重用而产生的构造物，而不是过程本身。 通过压缩式编程，代码变得更加简洁和易于理解，可以简化代码的设计和开发过程。 总结：本文介绍了一种名为压缩导向编程的有效编码方法，通过重构代码、提取重复代码片段和使用函数来简化代码。这种方法强调简洁、可读性和可扩展性，相比过于追求对象导向编程的复杂方法更为实用。","tags":["programming","OOP"],"categories":["文摘"]},{"title":"ChatGPT类服务汇总","path":"/2023/06/20/chatgpt/","content":"ChatGPT是由OpenAI开发的大型语言模型，可以理解和生成人类语言，具备生成连贯和上下文相关的回复的能力。 这类服务的主要目的是通过自然语言处理和对话系统技术，为用户提供智能对话和信息交流的能力。以下是ChatGPT类服务可能提供的功能和用途： 聊天机器人：ChatGPT类服务可以用作聊天机器人，与用户进行实时对话。用户可以提问问题、请求帮助、寻求建议，而ChatGPT将根据其训练的知识和上下文生成回复。 客户支持：许多公司和组织使用ChatGPT类服务来提供在线客户支持。用户可以通过对话框与机器人代表进行交流，寻求帮助、解决问题或获得产品或服务的相关信息。 智能助手：ChatGPT类服务可以用作个人助手应用程序的一部分，帮助用户管理日常任务、提供实用信息、制定行程或提供娱乐建议等。它可以根据用户的指令和上下文提供个性化的回复和服务。 教育辅助：ChatGPT类服务可以在教育领域用作学习辅助工具。学生可以向ChatGPT提问问题、请求解释或寻求学习建议。它可以提供参考资料、解答问题或引导学生进行学术研究。 娱乐和游戏：ChatGPT类服务可以用于创建有趣的娱乐和游戏体验。例如，它可以扮演虚拟角色，与用户进行角色扮演游戏，或参与有趣的智力游戏和谜题。 需要注意的是，ChatGPT类服务的功能和用途可能因具体应用程序或平台而异。不同的开发人员和组织可以根据其需求和目标，结合ChatGPT模型的能力来设计和定制各种对话系统应用。 ChatGPT类服务汇总：无需注册 Bard (web-browsing) Vitalentum OraChat Vicuna GPTGO (web-browsing) AnonChatGPT Perplexity AI (web-browsing) NoowAI Character AI BAI Chat iAsk AI (web-browsing) Phind AI (web-browsing) GPT4All (open-source) DeepAI Chat Teach Anything HuggingChat (web-browsing) Forefront AI 需要注册 Poe AI Easy-Peasy AI WriteSonic Sincode AI AI.LS LetsView Chat (only 10 messages allowed) CapeChat Open-Assistant (open-source) GlobalGPT Bing Chat JimmyGPT Codeium (mainly for coding) YouChat Frank AI OpenAI Playground 博客文章写作助手 Copy AI TextCortex AI Marmof HyperWrite WriterX 文档(PDF等)聊天机器人 AnySummary (3 per day) Sharly AI ChatDOC Humata AI Ask Your PDF ChatPDF FileGPT ResearchAide Pensieve AI PDFGPT.IO Docalysis 个人助理聊天机器人 Pi, your personal AI Kuki AI Replika YourHana AI","tags":["LLM","ChatGPT"],"categories":["资源"]}]